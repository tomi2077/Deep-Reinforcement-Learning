{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01 - Exit the dungeon!\n",
    "\n",
    "In this first lab, we will create by hand our first Reinforcement Learning environment.\n",
    "A lot of agents will be harmed in the process of solving the lab.\n",
    "\n",
    "## The environment\n",
    "\n",
    "The environment is a NxN array of integers. \n",
    "Each cell of this environment can have the following values:\n",
    "- 0 : empty cell\n",
    "- 1 : obstacle, non-traversable\n",
    "- 2 : lava\n",
    "- 3 : exit\n",
    "\n",
    "All border cells are obstacles.\n",
    "Upon initialization, the environment has:\n",
    "- N/2 obstacles placed randomly in the maze.\n",
    "- N/2 lava cells placed randomly in the cell.\n",
    "\n",
    "## The game\n",
    "\n",
    "The agent starts in a random empty cell, and has to reach the exit.\n",
    "The exit is randomly positioned in an other empty cell.\n",
    "\n",
    "At each timestep:\n",
    "- the agent decides on an action (move up, left, right or down)\n",
    "- the action is sent to the environment\n",
    "- the environment sends back observations, rewards and a boolean that indicates whether the environment terminated.\n",
    "\n",
    "The environment terminates if the agent reaches the exit, or if the environement reaches a time limit of N^2 timesteps.\n",
    "\n",
    "## Observations\n",
    "\n",
    "The agent receives a dictionary of observations:\n",
    "- target: relative coordinates of the exit \n",
    "- proximity: a 3x3 array that encodes for the value of the cells around the agent.\n",
    "\n",
    "## Rewards\n",
    "\n",
    "When acting, an agent receives a reward depending on the cell it ends up on:\n",
    "- if the agent moves towards an obstacle, it gets a reward of -5 and stays at its original position\n",
    "- if the agent is on a lava cell after its action, it receives a reward of -20\n",
    "- at each timestep, the agent receives an additional reward of -1\n",
    "- when the agent reaches the goal, it receives a reward of N**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from random import choice\n",
    "from numpy import mean, var\n",
    "import random\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Defining the environment.\n",
    "\n",
    "We will define the environment as a class.\n",
    "We are providing pseudo code which is incomplete and probably not completely error-free.\n",
    "\n",
    "You have to fill the blanks.\n",
    "We advise you to look at the pseudo-code for Part 2 and 3 to have an idea of how things work together.\n",
    "\n",
    "In order to make sure that your environment runs as intended, you will create a display function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dungeon:\n",
    "    \n",
    "    def __init__(self, N):\n",
    "        \n",
    "        # Numpy array that holds the information about the environment\n",
    "        self.dungeon = self.make_dungeon(N)\n",
    "        \n",
    "        # position of the agent and exit will be decided by resetting the environment.\n",
    "        self.position_agent = None\n",
    "        self.position_exit = None\n",
    "        \n",
    "        self.time_elapsed = 0\n",
    "        self.time_limit = N**2\n",
    "        \n",
    "        self.reward = 0\n",
    "        self.done = False\n",
    "        \n",
    "        # Allows me to call N elsewhere\n",
    "        self.N = N\n",
    "   \n",
    "    def make_dungeon(self, N):\n",
    "        # Create empty array defining dungeon area\n",
    "        dung_array = np.zeros((N,N))\n",
    "        \n",
    "        # Making dungeon borders = 1\n",
    "        dung_array[:,[0,-1]] = dung_array[[0,-1]] = 1\n",
    "        \n",
    "        # Random (x, y) coordinates for obstacles\n",
    "        obs_idx_x = np.random.randint(1, dung_array.shape[0]-1, N)\n",
    "        obs_idx_y = np.random.randint(1, dung_array.shape[1]-1, N)\n",
    "\n",
    "        # Assigning obstacles\n",
    "        dung_array[obs_idx_x[0:int(N/2)], obs_idx_y[0:int(N/2)]] = 1\n",
    "        # Assigning lava\n",
    "        dung_array[obs_idx_x[int(N/2):N], obs_idx_y[int(N/2):N]] = 2\n",
    "        \n",
    "        return dung_array\n",
    "    \n",
    "    def agent_and_exit_starting_location(self, dungeon):\n",
    "        empty_cells = np.argwhere(dungeon == 0)\n",
    "        \n",
    "        # Selecting a random one of those empty cells, then choosing similar for exit, not equal to agent location\n",
    "        empty_rand_idx_agent = np.random.randint(0, len(empty_cells)-1, 1)\n",
    "        empty_rand_idx_exit = choice([i for i in range(0, len(empty_cells)-1) if i != empty_rand_idx_agent[0]])\n",
    "\n",
    "        # Returning the starting location of the agent and the exit\n",
    "        agent_start = [empty_cells[empty_rand_idx_agent[0]][0], empty_cells[empty_rand_idx_agent[0]][1]]\n",
    "        exit_start = [empty_cells[empty_rand_idx_exit][0], empty_cells[empty_rand_idx_exit][1]]\n",
    "              \n",
    "        return agent_start, exit_start\n",
    "    \n",
    "    def get_observations(self, agent, exit, dungeon):\n",
    "        observation_dict = {}\n",
    "        \n",
    "        # Returning the values in the cells surrounding the agent\n",
    "        three_by_three = dungeon[agent[0]-1: agent[0]+2, agent[1]-1: agent[1]+2]\n",
    "        \n",
    "        observation_dict['observed'] = three_by_three\n",
    "        observation_dict['exit_loc'] = exit\n",
    "        \n",
    "        return observation_dict\n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        # action is 'up', 'down', 'left', or 'right' \n",
    "        agent_move = action\n",
    "\n",
    "        # modify the position of the agent\n",
    "        if agent_move == 'up':\n",
    "            self.position_agent[0] = self.position_agent[0]-1\n",
    "        if agent_move == 'down':\n",
    "            self.position_agent[0] = self.position_agent[0]+1\n",
    "        if agent_move == 'left':\n",
    "            self.position_agent[1] = self.position_agent[1]-1\n",
    "        if agent_move == 'right':\n",
    "            self.position_agent[1] = self.position_agent[1]+1\n",
    "        \n",
    "        # calculate total reward\n",
    "        if self.dungeon[self.position_agent[0], self.position_agent[1]] == 1:\n",
    "            # Removes 5 from total reward, plus 1 for the step taken \n",
    "            self.reward -= 6\n",
    "            # Resets movement, back to where agent was before\n",
    "            if agent_move == 'up':\n",
    "                self.position_agent[0] = self.position_agent[0]+1\n",
    "            elif agent_move == 'down':\n",
    "                self.position_agent[0] = self.position_agent[0]-1\n",
    "            elif agent_move == 'left':\n",
    "                self.position_agent[1] = self.position_agent[1]+1\n",
    "            elif agent_move == 'right':\n",
    "                self.position_agent[1] = self.position_agent[1]-1\n",
    "\n",
    "        elif self.dungeon[self.position_agent[0], self.position_agent[1]] == 2:\n",
    "            # Removed 20 for lava, plus 1 for the step taken\n",
    "            self.reward -= 21\n",
    "\n",
    "        elif self.dungeon[self.position_agent[0], self.position_agent[1]] == 3:\n",
    "            # N**2 for finding the exit, minus 1 for the step taken\n",
    "            self.reward += ((self.N**2)-1)\n",
    "            #print(\"Congratulations - You have found the exit! Your score was: %d\" % self.reward)\n",
    "            self.done = True\n",
    "\n",
    "        elif self.dungeon[self.position_agent[0], self.position_agent[1]] == 0:\n",
    "            # Just -1 for the step taken\n",
    "            self.reward -= 1\n",
    "        \n",
    "        elif self.dungeon[self.position_agent[0], self.position_agent[1]] == 4:\n",
    "            # Just -1 for the step taken\n",
    "            self.reward -= 1\n",
    "        \n",
    "        # calculate observations\n",
    "        \n",
    "        self.observations = self.get_observations(self.position_agent, self.position_exit, self.dungeon)\n",
    "        \n",
    "        # update time\n",
    "        self.time_elapsed += 1\n",
    "        \n",
    "        # verify secondary termination condition\n",
    "        if self.time_elapsed == self.time_limit:\n",
    "            #print(\"Gameover - Out of Moves. Your score was: %d\" % self.reward)\n",
    "            self.done = True\n",
    "        \n",
    "        # Mark the new position of the agent with a '4' (useful for debugging/visualizing)\n",
    "        self.dungeon[self.position_agent[0], self.position_agent[1]] = 4\n",
    "        \n",
    "        return self.observations, self.reward, self.done\n",
    "    \n",
    "    def display(self):\n",
    "        \n",
    "        # prints the environment\n",
    "        print(self.dungeon)\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        This function resets the environment to its original state (time = 0).\n",
    "        Then it places the agent and exit at new random locations.\n",
    "        \n",
    "        It is common practice to return the observations, \n",
    "        so that the agent can decide on the first action right after the resetting of the environment.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Resetting variables to zero:\n",
    "        self.time_elapsed = 0\n",
    "        self.time_limit = self.N**2\n",
    "        self.reward = 0\n",
    "        self.done = False\n",
    "        \n",
    "        # Make new dungeon\n",
    "        self.dungeon = self.make_dungeon(self.N)\n",
    "        \n",
    "        # position of the agent is a numpy array\n",
    "        self.position_agent, self.position_exit = self.agent_and_exit_starting_location(self.dungeon)\n",
    "        \n",
    "        # Mark the exit location with '3'\n",
    "        self.dungeon[self.position_exit[0], self.position_exit[1]] = 3\n",
    "        \n",
    "        # Mark the agent location with '4'\n",
    "        self.dungeon[self.position_agent[0], self.position_agent[1]] = 4\n",
    "        \n",
    "        # Calculate observations\n",
    "        self.observations = self.get_observations(self.position_agent, self.position_exit, self.dungeon)\n",
    "        \n",
    "    \n",
    "        return self.observations, self.time_elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3]\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 1. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 4. 0. 2. 0. 0. 2. 1.]\n",
      " [1. 0. 0. 2. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 2. 0. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 1. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 2. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 3. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "dungeon = Dungeon(10)\n",
    "dungeon.reset()\n",
    "\n",
    "print(dungeon.position_agent)\n",
    "dungeon.display()\n",
    "\n",
    "obs, reward, done = dungeon.step('right')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Defining a policy\n",
    "\n",
    "A policy tells the agent how to act depending on its current observation and internal beliefs.\n",
    "\n",
    "As a first simple case, we will define policy as a function that maps observations to actions.\n",
    "\n",
    "As your agent is stupid and doesn't have any way of learning what to do, in this first lab we will write by hand the policy.\n",
    "Try to come up with a strategy to terminate the game with the maximum reward.\n",
    "\n",
    "We advise you to start with a very simple policy, then maybe try a random policy, and finally an 'intelligent' policy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_policy(observation, action_lst):\n",
    "    # Checks observations and then decides to get to either the 0 or 3 square within observation area\n",
    "    \n",
    "    possible_routes = 0\n",
    "    exit_route_action = []\n",
    "    possible_actions = []\n",
    "    lava_action = []\n",
    "\n",
    "    for a, b, c in zip([0, 1, 1, 2],[1, 2, 0, 1],['up', 'right', 'left', 'down']):\n",
    "        # Calculates cost caused by obstacle in moving by using specified action\n",
    "        cost = dungeon.observations['observed'][a][b]\n",
    "        if cost == 0:\n",
    "            possible_routes += 1\n",
    "            possible_actions.append(c)\n",
    "        if cost == 3:\n",
    "            exit_route_action.append(c)\n",
    "        if cost == 4:\n",
    "            possible_routes += 1\n",
    "            possible_actions.append(c)\n",
    "        if cost == 2:\n",
    "            lava_action.append(c)\n",
    "        \n",
    "    # checks if exit route list is empty, if not then chooses that route\n",
    "    if not exit_route_action:\n",
    "        if len(possible_actions)>0:\n",
    "            # Chooses viable option randomly to avoid going back and forth\n",
    "            dir_choice = np.random.randint(0, possible_routes, 1)\n",
    "            action = possible_actions[int(dir_choice)]\n",
    "        else:\n",
    "            dir_choice = np.random.randint(0, len(lava_action), 1)\n",
    "            action = lava_action[int(dir_choice)]\n",
    "    else:\n",
    "        action = exit_route_action[0]\n",
    "    \n",
    "    return action\n",
    "\n",
    "\n",
    "def random_policy(observation, action_lst):\n",
    "    possible_actions = ['up', 'right', 'left', 'down']\n",
    "    rand_choice = np.random.randint(0, len(possible_actions)-1, 1)\n",
    "    action = possible_actions[int(rand_choice)]\n",
    "    \n",
    "    return action\n",
    "    \n",
    "    \n",
    "def intelligent_policy(observation, action_lst):\n",
    "    \n",
    "    dist_costs = []\n",
    "    obstacle_costs = []\n",
    "    optionality_costs = []\n",
    "    for a, b, c in zip([-1, 0, 0, 1],[0, 1, -1, 0],['up', 'right', 'left', 'down']):\n",
    "\n",
    "        # Calculate distance 'cost' from position of movement option to exit\n",
    "        pos = [dungeon.position_agent[0]+a, dungeon.position_agent[1]+b]\n",
    "        dist_vert = pos[0] - dungeon.observations['exit_loc'][0]\n",
    "        dist_hor = pos[1] - dungeon.observations['exit_loc'][1]\n",
    "        pythag_tot_dist =  dist_vert**2 + dist_hor**2\n",
    "        dist_costs.append(pythag_tot_dist)\n",
    "\n",
    "        # Calculate obstacle cost of moving in specific direction\n",
    "        pos_agent_obs = [1,1] # the position of the agent within the observations matrix\n",
    "        pos_agent_plus_step = [pos_agent_obs[0]+a, pos_agent_obs[1]+b]\n",
    "        cost = dungeon.observations['observed'][pos_agent_plus_step[0],pos_agent_plus_step[1]]\n",
    "\n",
    "        def calculate_obs_cost(cost):\n",
    "            if cost == 0:\n",
    "                cost = cost\n",
    "            elif cost == 1:\n",
    "                cost = 30\n",
    "            elif cost == 2:\n",
    "                cost = 20\n",
    "            elif cost == 3:\n",
    "                cost = cost-50\n",
    "            elif cost == 4:\n",
    "                cost = 5\n",
    "            return cost\n",
    "\n",
    "        obstacle_costs.append(calculate_obs_cost(cost))\n",
    "\n",
    "        # Calculates the costs of adjacent cells to the potential new cell\n",
    "        # If move is 'up' or 'down', need to check left and right to see the observed costs\n",
    "        total_next_options_cost = 0\n",
    "\n",
    "        if (c == 'up') | (c == 'down'):\n",
    "            left_cost = dungeon.observations['observed'][pos_agent_plus_step[0],pos_agent_plus_step[1]-1]\n",
    "            right_cost = dungeon.observations['observed'][pos_agent_plus_step[0],pos_agent_plus_step[1]+1]\n",
    "            total_next_options_cost =+ (calculate_obs_cost(left_cost) + calculate_obs_cost(right_cost)) / 30\n",
    "\n",
    "        elif (c == 'right') | (c == 'left'):\n",
    "            above_cost = dungeon.observations['observed'][pos_agent_plus_step[0]-1,pos_agent_plus_step[1]]\n",
    "            below_cost = dungeon.observations['observed'][pos_agent_plus_step[0]+1,pos_agent_plus_step[1]]\n",
    "            total_next_options_cost =+ (calculate_obs_cost(above_cost) + calculate_obs_cost(below_cost)) / 30\n",
    "\n",
    "        optionality_costs.append(total_next_options_cost)\n",
    "\n",
    "    # Summing all calculated costs\n",
    "    total_costs = []\n",
    "    mvmt_options = ['up', 'right', 'left', 'down']\n",
    "    for x, y, z in zip(dist_costs, obstacle_costs, optionality_costs):\n",
    "        total_costs_assoc_move = x + y + z\n",
    "        total_costs.append(total_costs_assoc_move)\n",
    "\n",
    "    # Implementing a check to stop it repeating steps, removes if repeated twice already from mvmt options list:\n",
    "    last_four_moves = action_lst[-4:]\n",
    "    if len(last_four_moves) == 4:\n",
    "        if (last_four_moves[-1:] == last_four_moves[-3:]) & (last_four_moves[-2:] == last_four_moves[-4:]):\n",
    "            remove1 = last_four_moves[-1:][0]\n",
    "            remove2 = last_four_moves[-2:][0]\n",
    "            mvmt_options = [i for i in mvmt_options if i not in (remove1, remove2)]\n",
    "            r1_index = mvmt_options.index(remove1)\n",
    "            r2_index = mvmt_options.index(remove2)\n",
    "            total_costs.pop(r1_index)\n",
    "            total_costs.pop(r2_index)\n",
    "            \n",
    "    last_seven_moves = action_lst[-8:]\n",
    "    if len(last_seven_moves) == 8:\n",
    "        for j, k in zip(mvmt_options, total_costs):\n",
    "            if last_seven_moves.count(j) >= 4:\n",
    "                mvmt_options.remove(j)\n",
    "                total_costs.remove(k)\n",
    "        \n",
    "    \n",
    "    # Returning the index of the minimum total cost and then choosing the action that's associated with it    \n",
    "    min_cost_idx = total_costs.index(min(total_costs))\n",
    "    action = mvmt_options[min_cost_idx]\n",
    "    \n",
    "    return action\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Evaluating your policy\n",
    "\n",
    "Now that you have the environment and policies, you can simulate runs of your games under different policies and evaluate the reward that particular policies will get upon termination of the environment. \n",
    "\n",
    "To that effect, we will create a function run_single_experiment, which will have as input:\n",
    "- an instance of an environment\n",
    "- a policy\n",
    "\n",
    "And it will return the reward obtained once the environment terminates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inital_surr_marks(observations):\n",
    "    initial_obs = []\n",
    "    for l, m in zip([0, 1, 1, 2],[1, 2, 0, 1]):\n",
    "        initial_obs.append(observations[0]['observed'][l][m])\n",
    "    return initial_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_exp(envir, policy):\n",
    "    \n",
    "    obs = envir.reset()\n",
    "    \n",
    "    # Seeting a loop to reset the agent position if it's surrounded by walls\n",
    "    initial_obs = get_inital_surr_marks(obs)\n",
    "\n",
    "    while initial_obs.count(1) == 4:\n",
    "        obs = envir.reset()\n",
    "        initial_obs = get_inital_surr_marks(obs)\n",
    "    \n",
    "    #print(obs)\n",
    "    done = False\n",
    "    action_lst = []\n",
    "    \n",
    "    while not done:\n",
    "        \n",
    "        action = policy(obs, action_lst)\n",
    "        action_lst.append(action)\n",
    "        #print(action)\n",
    "        obs, reward, done = envir.step(action)\n",
    "        #envir.display()\n",
    "\n",
    "    if reward < -90:\n",
    "        envir.display()\n",
    "        print(action_lst)\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Run - Basic Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulations - You have found the exit! Your score was: 82\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dungeon = Dungeon(10)\n",
    "run_single_exp(dungeon, basic_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameover - Out of Moves. Your score was: -100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-100"
      ]
     },
     "execution_count": 1007,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dungeon = Dungeon(10)\n",
    "run_single_exp(dungeon, basic_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Run - Random Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameover - Out of Moves. Your score was: -300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-300"
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dungeon = Dungeon(10)\n",
    "run_single_exp(dungeon, random_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulations - You have found the exit! Your score was: 75\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dungeon = Dungeon(10)\n",
    "run_single_exp(dungeon, random_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Run - Intelligent Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulations - You have found the exit! Your score was: 91\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dungeon = Dungeon(10)\n",
    "run_single_exp(dungeon, intelligent_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Evaluating your policy\n",
    "\n",
    "Now that you can evaluate how a policy performs on a particular environment, consider the following.\n",
    "Because of stochasticity of initial agent position and exit position, different runs will lead to different total rewards.\n",
    "\n",
    "To properly evaluate our policies, we must calculate the statistics over multiple runs.\n",
    "\n",
    "To that effect, we will create a function run_experiments, which will have as input:\n",
    "- an instance of an environment\n",
    "- a policy\n",
    "- a number of times that the experiment will be run\n",
    "\n",
    "It will return the maximum reward obtained over all the runs, the average and variance over the rewards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(envir, policy, number_exp):\n",
    "    \n",
    "    all_rewards = []\n",
    "    \n",
    "    for n in range(number_exp):\n",
    "        final_reward = 0\n",
    "        dungeon = Dungeon(10)\n",
    "        final_reward = run_single_exp(envir, policy)\n",
    "        all_rewards.append(final_reward)\n",
    "    \n",
    "    max_reward = max(all_rewards)\n",
    "    mean_reward = mean(all_rewards)\n",
    "    var_reward = var(all_rewards)\n",
    "    \n",
    "    \n",
    "    return max_reward, mean_reward, var_reward, all_rewards\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Reward - Basic Algo:  99\n",
      "Mean Reward - Basic Algo:  14.2003\n",
      "Variance of Reward - Basic Algo:  6730.32017991\n"
     ]
    }
   ],
   "source": [
    "dungeon = Dungeon(10)\n",
    "max_basic, mean_basic, var_basic, all_runs_basic = run_experiments(dungeon, basic_policy, 10000)\n",
    "print(\"Maximum Reward - Basic Algo: \", max_basic)\n",
    "print(\"Mean Reward - Basic Algo: \", mean_basic)\n",
    "print(\"Variance of Reward - Basic Algo: \", var_basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Reward - Random Algo:  99\n",
      "Mean Reward - Random Algo:  -219.525\n",
      "Variance of Reward - Random Algo:  24708.239374999997\n"
     ]
    }
   ],
   "source": [
    "dungeon = Dungeon(10)\n",
    "max_basic, mean_basic, var_basic, all_runs_random = run_experiments(dungeon, random_policy, 10000)\n",
    "print(\"Maximum Reward - Random Algo: \", max_random)\n",
    "print(\"Mean Reward - Random Algo: \", mean_random)\n",
    "print(\"Variance of Reward - Random Algo: \", var_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Reward - Intelligent Algo:  99\n",
      "Mean Reward - Intelligent Algo:  89.054\n",
      "Variance of Reward - Intelligent Algo:  892.0488839999999\n"
     ]
    }
   ],
   "source": [
    "dungeon = Dungeon(10)\n",
    "max_int, mean_int, var_int, all_runs_int = run_experiments(dungeon, intelligent_policy, 10000)\n",
    "print(\"Maximum Reward - Intelligent Algo: \", max_int)\n",
    "print(\"Mean Reward - Intelligent Algo: \", mean_int)\n",
    "print(\"Variance of Reward - Intelligent Algo: \", var_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4\n",
    "\n",
    "Draw some plots to compare how your different policies perform depending on the environment size.\n",
    "\n",
    "As the environment generation is also stochastic (random obstacles and lava), you might need to compute additional statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_rew_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_df = pd.DataFrame(all_runs_basic, columns = ['basic']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_df['random'] = all_runs_random\n",
    "runs_df['intell'] = all_runs_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>basic</th>\n",
       "      <th>random</th>\n",
       "      <th>intell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97</td>\n",
       "      <td>-420</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-100</td>\n",
       "      <td>-320</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91</td>\n",
       "      <td>-350</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-100</td>\n",
       "      <td>-320</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97</td>\n",
       "      <td>-365</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   basic  random  intell\n",
       "0     97    -420      97\n",
       "1   -100    -320      99\n",
       "2     91    -350      92\n",
       "3   -100    -320      93\n",
       "4     97    -365      92"
      ]
     },
     "execution_count": 1043,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHgAAAFgCAYAAADAT84SAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABpjUlEQVR4nO3de1yUZf7/8fcMBwVRYAA1PGQKpm4aFB5gVUzZdNVVlzysu+ZKWpbaQb7r17aD2pqpa0hakGWaWm1m31Z2q93aL7FBG5qY0VkNza+RBw4zghqKMPP7wx+TCBjiMAd8PR8PHg/mmvue+3Nd98w1M5+57usy2Gw2mwAAAAAAAOCxjK4OAAAAAAAAAFeGBA8AAAAAAICHI8EDAAAAAADg4UjwAAAAAAAAeDgSPAAAAAAAAB6OBA8AAAAAAICHI8GDJtm0aZMMBoMKCgrq3FdVVSWDwaAlS5bU2f7QoUOXdYyNGzc6INqWbceOHRo4cKDatGkjg8Gg/Pz8ererOQc1f15eXurUqZMmT56sffv2NUtsTTnvAJoX/bf7aGr/7evrqx49euihhx7SmTNnnBv0/9etWzfNmDHDJccG8CP6dPdxuX16fefsp2RkZGj16tVNjrG+839xf+5On9+vtL5XI29XB4Crw5gxY7Rjxw5dc801jd5n06ZNqqqq0h133NGMkXm+mTNnys/PT2+++ab8/f3Vs2fPS27/+uuvq3PnzqqurtaBAwe0dOlSjRgxQl9++aUCAwMdGltTzjsA90L/3Xya2n+fPHlS27dv1/Lly3Xy5Ek9/fTTTooYgKejT28+l9unN0VGRoYyMzOVnJzs8Meu4U6f351R35aGBA+cIiwsTGFhYa4Oo9HOnj2rVq1auTqMn2S1WrVv3z49/PDDGj58eKP2iYqKUkREhCTp5z//ucLDw/WLX/xCubm5+uUvf+nQ+DztvAOoy9Nex1dL//2LX/xC33zzjTZs2KA1a9bIaGRQNoCfRp/ePJrSp7srT3uOoDY+DcAp6hvq95e//EXR0dEKCAhQYGCg+vbtq+eee06SNGzYMGVnZ+vDDz+0D0kfNmyYfd9du3YpISFBAQEBatOmjUaMGKFdu3bVOe6aNWvUrVs3tW7dWgMGDFBubm6DwxBzcnI0adIkBQUFaeDAgZKkvLw8TZw4UZ07d5afn5+uv/56PfTQQ6qoqKh1nGHDhmnw4MF65513FBUVJT8/P0VHR+ujjz5SVVWVHnroIV1zzTUymUyaMWOGTp8+/ZNtVl5ernnz5ik8PFytWrXS9ddfr9TUVNlsNnvcXl5eslqtWrp0qQwGg7p169bIM/Kjdu3aSZLOnTtnLysoKNDtt9+u6667Tn5+furevbvuueceWSyWWvvm5eXpF7/4hUJCQuTv76/u3btrzpw5ddr24iGe69ev10033SQ/Pz8FBwcrPj5eubm5lx07gOZH/+2+/fdNN92kiooKlZSU2Mv+9a9/afTo0brmmmvk7++vG264QSkpKaqurq61b7du3TRt2jRt3bpVvXv3Vps2bRQTE6P//Oc/dY5z4bmIiYnRBx98UG88jTm3M2bMUOfOnbV7927FxcXZz83bb78tSVq9erW6deumdu3aafz48SouLr7sdgHQMPp09+zTa+LOzMzUTTfdZO+/MzIy7NvMmDFDmzdv1vfff28/Fxcep6SkRPfcc486deqkVq1aqVevXnr++ecvK46a+lz8HPnhhx90zz33KCQkRG3bttWvf/1r5ebmymAwaNOmTbX2z87O1ogRI9S2bVu1adNGI0eO1BdffOHw+qJ+jODBFamurlZVVVWdsp/yn//8R9OmTdN9992nVatWyWq1au/evTpx4oQkKT09XdOmTVN1dbX9DaYmEfHZZ58pPj5effr0sXdAK1asUHx8vHbu3Kkbb7xRkvTCCy/ogQce0MyZMzVp0iQdOHBAv/3tb+3HuNjvfvc7TZ06Vf/zP/9jr9Phw4cVFRWlGTNmqG3btvryyy/1pz/9SQcPHtTWrVtr7V9QUKAFCxbo4YcfVkBAgP77v/9b48aN07hx41RVVaVNmzbp66+/1oIFC9S+fXv9+c9/brB9rFarxowZoz179uhPf/qT+vbtq7ffflvJyckqLi7WE088oTFjxug///mPBg8erJkzZ2rWrFmN+oWj5pxVV1fr4MGDeuihh9S+fftab9ZHjhxR586d9dRTTyk4OFgHDx7UE088odGjR2vHjh2SpFOnTmnkyJEaMGCANm3apLZt2+rQoUM/maj5wx/+oJSUFM2cOVOPPfaYjEajdu7cqcOHDysuLu4n4wfgGPTfP/KU/vtihw4dUmBgoEJCQuxlBw8e1IgRI3TvvfeqdevW2r17t5YsWaLi4mKtWLGi1v4ffPCB9u3bp6VLl6p169Z69NFHNXbsWB06dEhBQUGSpA0bNuiBBx7QjBkzNGXKFBUUFGjq1Kk6efJkrcdq7LmVzn9Zmj59uv7whz8oPDxcy5Yt02233aa5c+dq//79SktL0/Hjx/XAAw9o7ty52rZt22W3DXC1oU//kaf26QcOHND999+vP/7xjwoNDVVKSoomTpyovXv3KiIiQo8++qiKi4uVl5env//975JkP055ebl+/vOfq6KiQkuWLNF1112nd999V/fcc4/Onj2re++997LjudBdd92l119/XUuWLFFMTIzee+89/e53v6uz3dtvv63x48drzJgxevnllyVJK1eu1JAhQ/TZZ5+pS5cuDqkvLsEGNMGLL75ok3TJv8WLF9fZ/ttvv7XZbDbbqlWrbMHBwZc8Rnx8vO3nP/95nfLbbrvNFhgYaLNYLPaysrIyW3BwsO3Xv/61zWaz2aqrq22dO3e2/fKXv6y17xtvvGGTZPv9739fJ7YHHnjgkvFYrVbbuXPnbC+99JLNYDDYSkpKasXq7e1tO3DggL3sb3/7m02SbcSIEbUe59e//rWtW7dulzzWm2++aZNke/HFF2uVz5w50+br62srLi622Ww227lz5+q0dUMaOmfh4eG2Xbt2XXLfc+fO2T744AObJNuePXtsNpvNlpeXZ5Nk+/TTT3/ymDXn/ZtvvrEZjUbb/PnzfzJeAM2D/ttz+++9e/fazp07ZzObzbYNGzbYvLy8bE8//fRP1vvxxx+3BQUF2aqrq+33XXvttbagoCCb2Wy2l9X066+88orNZvvxXIwcObLW427durXOuWjMubXZbLbf//73Nkm27Oxse9mnn35qk2Tr2bOnraqqyl4+f/58m7e3d60yALXRp3tun/7NN9/UiXv//v32suPHj9uMRqNt2bJl9rLf//73tk6dOtV5zD/96U+2Vq1a1drfZrPZZs2aZQsJCbGdO3eu1rFrzr/Ndv79oL7zULPN3r17bQaDwbZy5cpaj33vvffWaZsePXrYhg8fXmu7srIyW0hIiO3+++93WH3RMC7RwhXZvn278vLyav3t3LnzJ/fr37+/LBaLpk2bprfeeqvBDH59cnJyNHbsWPuvi9L5XxLGjRun7OxsSVJhYaEKCws1adKkWvuOHz9e3t71D1z79a9/XaesvLxcCxcuVI8ePdSqVSv5+Pjo9ttvl81m0zfffFNr2549e6p79+7227169ZIkjRw5stZ2vXr1UmFhoX1YZ0N1NBqNmjp1aq3yadOmqbKy0j6KpilqztmuXbuUkZGhPn36aPTo0fr666/t21RWVuqJJ55Qr1695OfnJx8fHw0ZMkSS7CtuRUZGKigoSLNnz9bLL7+s77777iePnZmZKavVqrvuuqvJ8QNwDPrvH3lK/92rVy/5+PjIZDJp5syZmj17tubNm1drm6NHj2r27Nm69tpr5evrKx8fHz3yyCM6ceKEioqKam0bGxur4OBg++2+fftKOv9LufTjuZg8eXKt/W677bY656Ix57ZGmzZtNHTo0Fr1kqSEhAR5eXnVKq+qqtLRo0cb1T7A1Yw+/Uee0qdfLDIyUpGRkfbb7du3V/v27e198qW88847GjhwoK677jpVVVXZ/0aOHKnS0lJ99dVXTY7ro48+ks1mq3MOJ06cWOv2N998owMHDuh3v/tdrRj8/f0VGxurnJwch9UXDeMSLVyRG264wT7hY42Lh4fWJz4+Xq+//rqefvppeyceHx+v1atXq1+/fpfc12w21zure8eOHe1zxNR8GGzfvn2tbby8vBQaGlrv49b3mElJScrMzNSf/vQnRUVFqU2bNtq1a5fmzp1bZ2naCz8kS5Kvr2+D5TWXSDX0xmY2m2UymeoMQ+zYsaP9/qa6+Jzdeuut6tKli5YsWaLXXntNkvTHP/5RTz/9tBYtWqS4uDi1bdtWhYWFSkxMtNc7MDBQ//73v7V06VLNmTNHJ0+e1M9+9jM99thjuu222+o9dmlpqSSpc+fOTY4fgGPQf//IU/rv7du3q3PnziouLtbq1auVnp6ugQMHavr06ZLOX0owbtw4HTlyREuWLLEn6TMyMrRs2bI69TaZTLVu18Rcs13NuejQoUOt7by9vWtdFlZTr586tzUu/DIoXbq9L4wHQMPo03/kKX36xS7uk6Xz/XJj+sCioiIVFBTIx8en3vtrPoM3RUPn8OL3hpofEWbOnKmZM2fWeZyuXbvWun0l9UXDSPDAZSZOnKiJEyfq1KlTev/997Vw4UKNGjVKhYWFl1wNxGQy6dixY3XKjx07Zu8oat4YLv61srq6utZklBcyGAy1bp85c0Z/+9vftGTJEt1///328s8//7xxFbwCJpNJZrNZlZWV9jclSfZ6X/zB+krUTKL82Wef2cu2bt2q6dOn65FHHrGXnTp1qs6+UVFReuONN1RVVaXdu3dr+fLlmjx5sj799FPdcMMNdbaveSP//vvvdf311zusDgCci/67Yc3Zf1/4BW748OHq16+fFixYoNtuu01t2rTRgQMHtHv3br300kuaNm2afb8333yzScerORfHjx+vVV5VVVXny0Jjzi0A90Sf3jBnfia/EiEhIWrfvr3WrFlT7/1X8rn7wnN43XXX2csvfm+oaYvly5crISGhzuNc2H5oPlyiBZcLCAjQ2LFjNXv2bB09etT+obFVq1Z1ZsaXzv+q8Pbbb9ea4PHkyZN68803FR8fL+n8CJHOnTvr9ddfr7VvRkZGo37NkM4vy1hdXV0nE37xTPHNIT4+XlartU78r7zyinx9fTVo0CCHHeuHH37QgQMHai2H+MMPP9Sp94svvtjgY3h7e2vQoEFaunSprFZrrcu9LpSQkCCj0dikGf0BuB/677qc1X+3atVKq1atUlFRkdLT0yWd77sl1ar3uXPn9MorrzTpGJ07d1aXLl3qTHJck9i/UGPOLQD3Rp9elzM/kzdGQ+di1KhR2rt3r7p27aqYmJg6f23btm3yMQcOHCiDwVCnDS6+ff3116tbt2768ssv643hp0aE1aeh+qJhjOCBSyxatEjHjx/XLbfcovDwcBUWFmrt2rWKioqyJxr69Omj9PR0vfbaa+rRo4fatm2r66+/Xo8++qjeeustjRgxQgsXLpTBYNDKlSv1ww8/aNGiRZIko9GoxYsX684779SsWbM0adIkHTx4UCtWrFBgYOAlf42oERgYqEGDBiklJUXXXHONQkNDtXHjRn3//ffN2jaS9Mtf/lKDBw/W3XffreLiYv3sZz/TP/7xD73wwgv2meabKj8/XyUlJbLZbDp69KieeeYZmc3mWrPrjxo1Sps3b1bfvn0VERGhv/71r3VWx3rrrbf0/PPPa8KECbruuut0+vRprV27Vm3btlVsbGy9x+7Ro4fmz5+v1atX6+TJkxo3bpy8vLy0a9cu9erVS1OmTGlyvQA4B/33pTVn/32xcePGqX///nryySc1b9489e7dW9dee60efvhheXl5ycfHR6mpqU1+/JpzMWvWLCUlJek3v/mNCgoKtHz5cvsqOjUac24BuB/69EtzZp/eGH369JHZbNazzz6rmJgYtW7dWn379tX8+fP12muvaciQIZo/f76uv/56nT59Wnv37tUHH3ygv/3tb00+5vXXX6/f/va3evTRR2W1WnXzzTcrKyvLPjq05hwaDAalpaVp/Pjxqqys1OTJkxUaGqrjx48rNzdXXbt2VXJyskPqi4aR4IFLDBw4UGvXrtX8+fNlNpvVvn173XrrrVq6dKl9m4ULF2rfvn2aNWuWTp06pfj4eL3//vvq16+f3n//fT388MP6/e9/L5vNpkGDBik7O7vWMqw1+6Wmpurll1/WDTfcoFdeeUW/+tWvFBgY2Kg4X331Vd1zzz2aO3eu/Pz8NHnyZK1Zs0Zjx451eJtcyGg06u2339ZDDz2klStXqrS0VN26ddPq1av1wAMPXNFjXzhBWlhYmG644Qa98847tSaee/rpp2Wz2fTwww9LkkaPHq1XX31VAwYMsG8TGRkpPz8/LV26VEePHlXbtm3Vv39//e///u8l59h58sknFRERofT0dG3evFlt2rRRv379dOutt15RvQA4B/33pTVn/12fxx9/XCNHjtS6des0f/58ZWRkaN68eZo+fbpMJpPuuOMOde3aVXfeeWeTHn/mzJk6deqUVq9erVdffVU33HCDtm7dWusSMEmNPrcA3At9+qU5u0//KbNmzdLOnTv10EMP6cSJE7r22mt16NAhBQYGKjc3V3/605+0cuVKff/99woKCtL111/f4NyYl+P5559X27Zt9ec//1mVlZUaPny40tLSNHbs2FrncPTo0crJydGyZcs0a9YsVVRUqGPHjho0aFCTfshtqL5omMF2qWnDgRYmLy9PAwYM0JYtW3T77be7OhwAQCPRfwNAy0Gf7vlWrVqlhQsX6tChQ3UmUIbrkOBBi/Xtt98qLS1NQ4YMUbt27fT111/riSeekK+vr7744gv5+/u7OkQAQD3ovwGg5aBP93xvvfWWvvjiC0VFRcloNOqDDz7Qk08+qfHjx2vr1q2uDg8X4BIttFh+fn764osvtGXLFlksFgUHByshIUErVqzgjQQA3Bj9NwC0HPTpnq9t27bKyMjQihUrdPr0aXXq1En33XefHnvsMVeHhoswggcAAAAAAMDDsUw6AAAAAACAhyPBAwAAAAAA4OFI8AAAAAAAAHg4EjwAAAAAAAAejgQPAAAAAACAhyPBAwAAAAAA4OFI8AAAAAAAAHg4EjwAAAAAAAAejgQPAAAAAACAhyPBAwAAAAAA4OFI8AAAAAAAAHg4EjwAAAAAAAAejgQPAAAAAACAhyPBAwAAAAAA4OFI8AAAAAAAAHg4EjwAAAAAAAAejgQPAAAAAACAhyPBAwAAAAAA4OFI8AAAAAAAAHg4EjwAAAAAAAAeztvVATjLkSNHXB3CJYWGhqqkpMTVYbgc7fAj2uI82uFHTWmL8PDwZorGfTm6v/eE56C7x+ju8UnE6CjuHqO7xyc1Pcarsb+Xmv8zvic8Z65ES6+f1PLrSP08m6P7fEbwAAAAAAAAeDgSPAAAAAAAAB6OBA8AAAAAAICHI8EDAAAAAADg4UjwAAAAAAAAeDgSPAAAAAAAAB6OBA8AAAAAAICHI8EDAAAAAADg4bxdHQAAoOUoKSlRWlqaTpw4IYPBoISEBI0ePVrbtm3Te++9p3bt2kmSpk6dqptuukmStH37dmVlZcloNCopKUlRUVGSpIMHDyotLU2VlZWKjo5WUlKSDAaDq6oGAAAAuDUSPAAAh/Hy8tLtt9+u7t27q6KiQg8++KD69esnSRozZozGjRtXa/vCwkLl5uZq9erVslgsWrp0qdasWSOj0aj169dr9uzZioyM1PLly5Wfn6/o6GhXVAsAAABwe1yiBQBwmODgYHXv3l2S5Ofnp06dOslsNje4fV5enuLi4uTj46P27durY8eOKigokMViUUVFhXr27CmDwaChQ4cqLy/PWdUAAAAAPA4jeJpJp/Xrm7Tf93fe6eBIAMA1ioqK9O233yoiIkJ79+7Vu+++q5ycHHXv3l3Tp09XQECAzGazIiMj7fuYTCaZzWZ5eXkpJCTEXh4SEtJgoigzM1OZmZmSpBUrVig0NNSh9fD29nb4Yzqau8foivj+b+GBy9r+tMrs/1+7soejw3EIdz/PkvvH6O7xSZ4RIwDgR+Hvd2rSfkeGfe/gSEjwAACawZkzZ5SSkqIZM2bI399ft956qyZOnChJeu2117RlyxbNmTNHNput3v0bKq9PQkKCEhIS7LdLSkquLPiLhIaGOvwxHc3dY3T3+C7mrrF6Qju6e4zuHp/U9BjDw8ObIRoAgCfhEi0AgENVVVUpJSVFQ4YM0cCBAyVJQUFBMhqNMhqNGjFihA4cOD+6IiQkRKWlpfZ9zWazTCZTnfLS0lKZTCbnVgQAAADwICR4AAAOY7PZtG7dOnXq1Eljx461l1ssFvv/u3btUpcuXSRJMTExys3N1blz51RUVKSjR48qIiJCwcHB8vPz0/79+2Wz2ZSTk6OYmBin1wcAAADwFFyiBQBwmH379iknJ0ddu3bVggULJJ1fEv3DDz/UoUOHZDAYFBYWprvuukuS1KVLF8XGxio5OVlGo1EzZ86U0Xj+t4dZs2YpPT1dlZWVioqKYgUtAAAA4BJI8AAAHKZXr17atm1bnfKbbrqpwX0SExOVmJhYp7xHjx5KSUlxaHwAAABAS8UlWgAAAAAAAB6OBA8AAAAAAICHI8EDAAAAAADg4UjwAAAAAAAAeDgmWQYAAG7r9KoyV4cAAADgERjBAwAAAAAA4OFI8AAAAAAAAHg4p1yiVVlZqcWLF6uqqkrV1dUaNGiQJk+erFOnTik1NVXFxcUKCwvT/PnzFRAQIEnavn27srKyZDQalZSUpKioKEnSwYMHlZaWpsrKSkVHRyspKUkGg8EZ1QAAAAAAAHBLThnB4+Pjo8WLF2vVqlX685//rPz8fO3fv18ZGRnq27ev1q5dq759+yojI0OSVFhYqNzcXK1evVoPP/ywNmzYIKvVKklav369Zs+erbVr1+rYsWPKz893RhUAAAAAAADcllMSPAaDQa1bt5YkVVdXq7q6WgaDQXl5eYqPj5ckxcfHKy8vT5KUl5enuLg4+fj4qH379urYsaMKCgpksVhUUVGhnj17ymAwaOjQofZ9AAAAAAAArlZOW0XLarVq4cKFOnbsmEaOHKnIyEiVlZUpODhYkhQcHKzy8nJJktlsVmRkpH1fk8kks9ksLy8vhYSE2MtDQkJkNpvrPV5mZqYyMzMlSStWrFBoaGhzVc2hPCXO5uLt7X3Vt0EN2uI82uFHtAUAAACAhjgtwWM0GrVq1SqdPn1aTz75pA4fPtzgtjab7bLK65OQkKCEhAT77ZKSksYH60KeEmdzCQ0NverboAZtcR7t8KOmtEV4eHgzRQMAAADAnTh9Fa02bdqoT58+ys/PV2BgoCwWiyTJYrGoXbt2ks6PzCktLbXvYzabZTKZ6pSXlpbKZDI5twIAAAAAAABuxikJnvLycp0+fVrS+RW1Pv/8c3Xq1EkxMTHKzs6WJGVnZ6t///6SpJiYGOXm5urcuXMqKirS0aNHFRERoeDgYPn5+Wn//v2y2WzKyclRTEyMM6oAAAAAAADgtpxyiZbFYlFaWpqsVqtsNptiY2N18803q2fPnkpNTVVWVpZCQ0OVnJwsSerSpYtiY2OVnJwso9GomTNnymg8n4uaNWuW0tPTVVlZqaioKEVHRzujCgAAAAAAAG7LKQmea6+9Vn/+85/rlLdt21aLFi2qd5/ExEQlJibWKe/Ro4dSUlIcHiMAAAAAAICncvocPAAAAAAAAHAsEjwAAAAAAAAejgQPAAAAAACAhyPBAwAAAAAA4OGcMskyAAAAgJbnrbfeUlZWlgwGg7p06aI5c+aosrJSqampKi4uVlhYmObPn6+AgABJ0vbt25WVlSWj0aikpCRFRUVJkg4ePKi0tDRVVlYqOjpaSUlJMhgMLqwZAHgeRvAAAAAAuGxms1n//Oc/tWLFCqWkpMhqtSo3N1cZGRnq27ev1q5dq759+yojI0OSVFhYqNzcXK1evVoPP/ywNmzYIKvVKklav369Zs+erbVr1+rYsWPKz893XcUAwEOR4AEAAADQJFarVZWVlaqurlZlZaWCg4OVl5en+Ph4SVJ8fLzy8vIkSXl5eYqLi5OPj4/at2+vjh07qqCgQBaLRRUVFerZs6cMBoOGDh1q3wcA0HhcogUAAADgsplMJv3qV7/SPffcI19fX91444268cYbVVZWpuDgYElScHCwysvLJZ0f8RMZGVlrf7PZLC8vL4WEhNjLQ0JCZDab6z1mZmamMjMzJUkrVqxQaGhoc1VPkuTt7d3sx3Clll4/qeXXkfp5rtDQUIfXjwQPAAAAgMt26tQp5eXlKS0tTf7+/lq9erVycnIa3N5ms11WeX0SEhKUkJBgv11SUtL4gJsgNDS02Y/hSi29flLLryP1c73wJu5XUlLS5PqFh9d/VC7RAgAAAHDZPv/8c7Vv317t2rWTt7e3Bg4cqP379yswMFAWi0WSZLFY1K5dO0nnR+aUlpba9zebzTKZTHXKS0tLZTKZnFsZAGgBSPAAAAAAuGyhoaH65ptvdPbsWdlsNn3++efq1KmTYmJilJ2dLUnKzs5W//79JUkxMTHKzc3VuXPnVFRUpKNHjyoiIkLBwcHy8/PT/v37ZbPZlJOTo5iYGFdWDQA8EpdoAQAAALhskZGRGjRokBYuXCgvLy9169ZNCQkJOnPmjFJTU5WVlaXQ0FAlJydLkrp06aLY2FglJyfLaDRq5syZMhrP/948a9Yspaenq7KyUlFRUYqOjnZl1QDAI5HgAQAAANAkkydP1uTJk2uV+fj4aNGiRfVun5iYqMTExDrlPXr0UEpKSrPECABXCy7RAgAAAAAA8HAkeAAAAAAAADwcCR4AAAAAAAAPR4IHAAAAAADAw5HgAQAAAAAA8HAkeAAAAAAAADwcCR4AAAAAAAAPR4IHAAAAAADAw5HgAQAAAAAA8HAkeAAAAAAAADwcCR4AAAAAAAAPR4IHAAAAAADAw5HgAQAAAAAA8HDerg4AANBylJSUKC0tTSdOnJDBYFBCQoJGjx6tU6dOKTU1VcXFxQoLC9P8+fMVEBAgSdq+fbuysrJkNBqVlJSkqKgoSdLBgweVlpamyspKRUdHKykpSQaDwYW1AwAAANwXI3gAAA7j5eWl22+/XampqVq2bJneffddFRYWKiMjQ3379tXatWvVt29fZWRkSJIKCwuVm5ur1atX6+GHH9aGDRtktVolSevXr9fs2bO1du1aHTt2TPn5+a6rGAAAAODmSPAAABwmODhY3bt3lyT5+fmpU6dOMpvNysvLU3x8vCQpPj5eeXl5kqS8vDzFxcXJx8dH7du3V8eOHVVQUCCLxaKKigr17NlTBoNBQ4cOte8DAAAAoC4u0QIANIuioiJ9++23ioiIUFlZmYKDgyWdTwKVl5dLksxmsyIjI+37mEwmmc1meXl5KSQkxF4eEhIis9lc73EyMzOVmZkpSVqxYoVCQ0MdWg9vb2+HP6ajuXuMVxLfaZU5OJqf5q5t6e7nWXL/GN09PskzYgQAuCcSPAAAhztz5oxSUlI0Y8YM+fv7N7idzWa7rPL6JCQkKCEhwX67pKSk8YE2QmhoqMMf09HcPUZ3j+9i7hqrJ7Sju8fo7vFJTY8xPDy8GaIBAHgSpyR4Gpp0c9u2bXrvvffUrl07SdLUqVN10003SWLSTQDwVFVVVUpJSdGQIUM0cOBASVJgYKAsFouCg4NlsVjs/X5ISIhKS0vt+5rNZplMpjrlpaWlMplMzq0IAAAA4EGcMgdPQ5NuStKYMWO0atUqrVq1yp7cYdJNAPBMNptN69atU6dOnTR27Fh7eUxMjLKzsyVJ2dnZ6t+/v708NzdX586dU1FRkY4ePaqIiAgFBwfLz89P+/fvl81mU05OjmJiYlxSJwAAAMATOGUET3BwsH3uhQsn3WxIQ5NuhoWF2SfdlGSfdDM6OtoZ1QAA/IR9+/YpJydHXbt21YIFCySdH505YcIEpaamKisrS6GhoUpOTpYkdenSRbGxsUpOTpbRaNTMmTNlNJ7/7WHWrFlKT09XZWWloqKi6OsBAACAS3D6HDwXTrq5d+9evfvuu8rJyVH37t01ffp0BQQEeMSkm83FU+JsLkws+CPa4jza4Uee0Ba9evXStm3b6r1v0aJF9ZYnJiYqMTGxTnmPHj2UkpLi0PgAAACAlsqpCZ6LJ9289dZbNXHiREnSa6+9pi1btmjOnDkeMelmc/GUOJuLJ0x+6Cy0xXm0w4+a0hZMugkAAABcHZwyB49U/6SbQUFBMhqNMhqNGjFihA4cOCCJSTcBAAAAAAAuh1MSPA1NummxWOz/79q1S126dJHEpJsAAAAAAACXwymXaDU06eaHH36oQ4cOyWAwKCwsTHfddZckJt0EAAAAAAC4HE5J8DQ06WbNsuj1YdJNAAAAAACAxnHaHDwAAAAAAABoHiR4AAAAAAAAPBwJHgAAAAAAAA9HggcAAAC4Cu3YsaPe8p07dzo5EgCAIzhlkmUAgNRp/fom7ff9nXc6OBIAAKR169YpNja2Tvlzzz2nQYMGuSAiAMCVIMEDAAAAXEWOHz8uSbJarSoqKpLNZqt1n6+vr6tCAwBcARI8AAAAwFXkvvvus/9/77331rovKChIkyZNcnZIAAAHIMEDAAAAXEVee+01SdLixYv12GOPuTgaAICjMMkyAAAAcBUiuQMALQsjeAAAtVRXV+vDDz/Ut99+qzNnztS6b/bs2S6KCgDgaEVFRXr11Vd16NChOv39s88+66KoAABNRYIHAFDL008/rcOHDysqKkqBgYGuDgcA0EzWrFmjDh06aPr06WrVqpWrwwEAXCESPACAWvLz8/Xss8/Kz8/P1aEAAJpRYWGhli5dKqORWRsAoCWgNwcA1NK5c2edOnXK1WEAAJpZ7969dejQIVeHAQBwEEbwAABquffee7Vu3TrdeOONdS7Rio+Pd1FUAABHCwsL07JlyzRgwAAFBQXVum/KlCmuCQoA0GQkeAAAtbz//vvau3evTp8+LV9fX3u5wWAgwQMALcjZs2d18803q7q6WqWlpa4OBwBwhUjwAABq+cc//qGVK1eqc+fOrg4FANCM5syZ4+oQAAAORIIHAFBLUFCQQkNDXR0GAMAJCgsLtXPnTpWVlWnmzJk6cuSIzp07p2uvvdbVoQEALhOTLAMAahkzZozWrl2r/fv36/jx47X+AAAtx44dO7R48WKZzWbl5ORIkioqKrRlyxYXRwYAaIpGjeAxm83y9fVVQECAvezUqVOqrKyUyWRqtuAAAM63YcMGSdLHH39c577XXnvN2eEAAJrJtm3b9Oijj6pbt27asWOHJOnaa69lZS0A8FCNSvCsWrVK99xzT60Ej9ls1rp16/TEE080W3AAAOcjiQMAV4eysrI6l2IZDAYZDAYXRQQAuBKNSvAcOXJEXbt2rVXWtWtXff/9980SFADA9UpKSmQ2m2UymZiTBwBaoO7duysnJ6fWCokffvihIiIiGv0Yp0+f1rp16/Tdd9/JYDDonnvuUXh4uFJTU1VcXKywsDDNnz/f/kPx9u3blZWVJaPRqKSkJEVFRUmSDh48qLS0NFVWVio6OlpJSUkkmgDgMjUqwdOuXTsdO3ZMHTt2tJcdO3ZMbdu2bbbAAACuYbFY9NRTT2n//v1q27atTp48qZ49e+r+++/nslwAaEGSkpL0+OOPKysrS2fPntWyZct05MgRPfLII41+jBdffFFRUVH6r//6L1VVVens2bPavn27+vbtqwkTJigjI0MZGRmaNm2aCgsLlZubq9WrV8tisWjp0qVas2aNjEaj1q9fr9mzZysyMlLLly9Xfn6+oqOjm7H2ANDyNGqS5VtuuUUpKSn6+OOPVVhYqN27dyslJUXDhw9v7vgAAE62fv16XXvttXrxxRf1/PPP68UXX1S3bt20fv16V4cGAHCgTp066amnntLIkSP1m9/8RsOGDVNKSoquueaaRu3/ww8/6Ouvv7Z/J/D29labNm2Ul5dnHxUUHx+vvLw8SVJeXp7i4uLk4+Oj9u3bq2PHjiooKJDFYlFFRYV69uwpg8GgoUOH2vcBADReo0bwTJgwQd7e3nrppZdUWlqqkJAQDR8+XGPHjm3u+AAATrZv3z4lJyfL2/v8W0Tr1q01bdo03X333S6ODADgaK1atVJcXFyT9i0qKlK7du2Unp6u//u//1P37t01Y8YMlZWVKTg4WJIUHBys8vJySefn8IyMjLTvbzKZZDab5eXlpZCQEHt5SEiIzGbzFdQKAK5OjUrwGI1GjRs3TuPGjWvueAAALtamTRsVFhaqW7du9rIjR47I39/fdUEBABxu0aJF9c5z4+3trZCQEA0YMEAxMTEN7l9dXa1vv/1Wd9xxhyIjI/Xiiy8qIyOjwe1tNttlldcnMzNTmZmZkqQVK1Y0+xxx3t7eLXoeupZeP6nl15H6ea7Q0FCH16/BBM9XX32lPn36SJK++OKLBh/ghhtucFgwAADXGzdunJYuXarhw4crLCxMxcXFev/99zVlyhRXhwYAcKA+ffooOztb8fHxCg0NVUlJiXJycjR48GDZbDY9++yzGjdunMaPH1/v/iEhIQoJCbGPyhk0aJAyMjIUGBgoi8Wi4OBgWSwWtWvXzr59aWmpff+aifwvLi8tLW1wzreEhAQlJCTYb5eUlFxxO1xKTbu0VC29flLLryP1c73wJu5XUlLS5PqFh9d/1AYTPBs2bFBKSook6dlnn613G4PBoGeeeeaygwEAuK+EhAR17NhR//nPf3T48GEFBwfr/vvvJ6EPAC3MZ599pocfflidO3e2lw0ZMkRpaWl64oknNHDgQD311FMNJniCgoIUEhKiI0eOKDw8XJ9//rk6d+6szp07Kzs7WxMmTFB2drb69+8vSYqJidHatWs1duxYWSwWHT16VBERETIajfLz89P+/fsVGRmpnJwcjRo1yiltAAAtSYMJnprkjiSlpaU5JRgAgHu44YYbSOgAQAv3/fffq0OHDrXKwsLCdOTIEUlSRESEysrKLvkYd9xxh9auXauqqiq1b99ec+bMkc1mU2pqqrKyshQaGqrk5GRJUpcuXRQbG6vk5GQZjUbNnDlTRuP5NV9mzZql9PR0VVZWKioqihW0AKAJGjUHz8W++OILeXl5qXfv3o6OBwDgAq+99lqjtuMyLQBoOXr37q309HRNmTLFPuHxtm3b1KtXL0myj+K8lG7dumnFihV1yhctWlTv9omJiUpMTKxT3qNHj1o/MAMALl+jEjyLFy/W1KlT1atXL2VkZOjtt9+W0WjUyJEj6+2gAQCe5cK5DyorK/XRRx8pIiLCfl1wQUGBBg4c6MIIAQCONm/ePL3wwguaP3++rFarvLy8NGDAAM2ZM0fS+clN77//fhdHCQBorEYleL777jv17NlTkvTee+9p8eLFat26tR599FESPADQAtR8mJekp556Svfff78GDRpkL/voo4+0Y8cOV4QGAGgmAQEBeuCBB2S1WlVeXq527drZL5mSGp7EEwDgnhqV4KlZuvDYsWOSZJ+I7fTp0406SElJidLS0nTixAkZDAYlJCRo9OjROnXqlFJTU1VcXKywsDDNnz9fAQEBkqTt27crKytLRqNRSUlJioqKkiQdPHhQaWlpqqysVHR0tJKSkupd3hEA0DSffPKJ7rvvvlpl/fv3V3p6uosiAgA4SlFRkdq3by9JOn78eK37iouL7f9fPDcPAMD9NSrBc/3112vjxo2yWCz2WfCPHTumtm3bNuogXl5euv3229W9e3dVVFTowQcfVL9+/fT++++rb9++mjBhgjIyMpSRkaFp06apsLBQubm5Wr16tSwWi5YuXao1a9bIaDRq/fr1mj17tiIjI7V8+XLl5+czCRsAOFDHjh31zjvvaPTo0fayd999Vx07dnRhVAAAR/jDH/6gLVu2SFKdZP6FGjs3GwDAfTQqwTN37ly9+eabateuncaNGydJOnLkSK0P/5cSHBxsn6DNz89PnTp1ktlsVl5enpYsWSJJio+P15IlSzRt2jTl5eUpLi5OPj4+at++vTp27KiCggKFhYWpoqLCfrnY0KFDlZeXR4IHABzo7rvv1pNPPqm///3v9kk3vby89F//9V+uDg0AcIVqkjsSSRwAaGkaleBp27atfvvb39Yqu+mmm5p0wKKiIn377bf2ZRdrEj/BwcEqLy+XJJnNZkVGRtr3ufALRkhIiL08JCREZrO53uNkZmYqMzNTkrRixQqFhoY2KV5n85Q4m4u3t/dV3wY1aIvzaIcf+wVntcV1112nNWvWaP/+/Tpx4oSCgoLUs2dPeXs3aeFFAAAAAE7Q6E/rhw4d0tdff62TJ0/a5+SRLm/J3DNnziglJUUzZsyQv79/g9td+PiNKa9PQkKCEhIS7LdLSkoava8reUqczaVmxR7QFjVohx/7haa0RVMnyPT29lafPn1ktVrtZVartdbkmwAAz7No0aJGzV/52GOPOSEaAIAjNSrBk5mZqc2bN6tfv37Kz89XVFSUPvvsM8XExDT6QFVVVUpJSdGQIUPsS+0GBgbKYrEoODhYFotF7dq1k3R+ZM6FS/aazWaZTKY65aWlpTKZTI2OAQDw0w4ePKgNGzbo8OHDqqysrHUfw/kBwLMNHz7c1SEAAJpJoxI8f/vb3/TQQw+pd+/eSkpK0oIFC/TJJ5/oww8/bNRBbDab1q1bp06dOmns2LH28piYGGVnZ2vChAnKzs62T+AcExOjtWvXauzYsbJYLDp69KgiIiJkNBrl5+en/fv3KzIyUjk5ORo1alQTqg0AaEhaWppuvvlm3XPPPWrVqtVl75+enq49e/YoMDBQKSkpkqRt27bpvffesyfyp06dar/Ul1UTAcB5hg0b5uoQAADNpFEJnvLycvXu3VuSZDAYZLVaFR0drbVr1zbqIPv27VNOTo66du2qBQsWSDr/4X7ChAlKTU1VVlaWQkNDlZycLEnq0qWLYmNjlZycLKPRqJkzZ9ovC5g1a5bS09NVWVmpqKgoJlgGAAcrKSnR1KlTm5xMGTZsmEaNGqW0tLRa5WPGjLFP1F+DVRMBwLmysrIatR0jfQDA8zQqwWMymVRUVKT27dvrmmuu0e7du9W2bdtGT7jZq1cvbdu2rd77Fi1aVG95YmKiEhMT65T36NHD/oswAMDx+vfvr08//dQ+kuZy9enTR0VFRY3allUTAcC5Pvjgg0ZtR4IHADxPozI048eP1/fff6/27dtr4sSJWr16taqqqpSUlNTc8QEAnOzcuXN68skn1atXLwUFBdW6b968eU1+3HfffVc5OTnq3r27pk+froCAAI9YNdETVnJz9xivJL7TKnNwND/NXdvS3c+z5P4xunt8UvPHuHjx4mZ7bACAazUqwXPhtbrR0dF68cUXVVVVpdatWzdXXAAAF+ncubM6d+7s0Me89dZbNXHiREnnJ2resmWL5syZ4xGrJnrCSm7uHqO7x3cxd43VE9rR3WN09/ikpsfY1FUTT548qU8++UQnTpzQuHHjZDabZbPZaiXZAQCeodHLpNeoqqrS4cOH1aFDh+aIBwDgYpMmTXL4Y144EmjEiBFauXKlJFZNBABX+uqrr5SSkqLu3btr3759GjdunI4dO6a///3vevDBB10dHgDgMl0ywfPDDz/o9ddfV2FhoXr27KmEhAQtWrRIRUVF8vX11YIFC9SvXz9nxQoAcJKqqiodOXJE5eXltcpvuOGGJj2exWJRcHCwJGnXrl3q0qWLJFZNBABX2rRpkx544AH17dvXPvVCRESEDhw44OLIAABNcckEzwsvvKBTp06pf//+ysvLU25urn75y19qxIgR+ve//62tW7eS4AGAFmbv3r1avXq1zp07p4qKCvn5+enMmTMKCQnRM88885P7P/XUU/rqq6908uRJ3X333Zo8ebK+/PJLHTp0SAaDQWFhYbrrrrsksWoiALhScXGx+vbtW6vM29tb1dXVLooIAHAlLpng+eyzz/TMM8+odevWiouL05133qlRo0bJaDTq1ltv1datW50VJwDASTZv3qxx48Zp7NixSkpK0osvvqj/+Z//ka+vb6P2f+CBB+qUXWo1FlZNBADX6Ny5s/Lz82utmvj555+ra9eurgsKANBkxkvdee7cOftEygEBAWrdurX9l1Wj0XhZk2ACADzDkSNHNHr06FplEyZM0Ntvv+2iiAAAzeH222/X008/rWeeeUaVlZV6/vnnlZ6ermnTprk6NABAE1xyBI/NZlNRUZE9kVPfbQBAy+Lv76+Kigq1adNGQUFBKiwsVEBAgM6cOePq0AAADtSzZ0+tWrVKH3zwgVq3bq3Q0FA98cQTrKAFAB7qkgmes2fP6t57761VdvFtAEDLMnDgQH3yyScaPHiwhg8frscee0xeXl6KjY11dWgAAAf6+9//rnHjxmn8+PG1yt966y2NHTvWRVEBAJrqkgme1157zVlxAADcxIwZM+z//+pXv1JkZKQqKipqzdEAAPB8b7zxhsaNG1dvOQkeAPA8l0zwAADQq1cvlZWV6eWXX9btt9/u6nAAAFfoiy++kCRZrVb7/zWOHz8uPz8/V4QFALhCJHgAAJLOz6v273//W4cOHVLHjh1166236uzZs3r99df13nvvqU+fPq4OEQDgAM8++6wkqbKy0v6/JBkMBgUFBemOO+5wVWgAgCtAggcAIEl66aWXlJubq+uvv14fffSRCgoK9M033ygyMlLLli1j2VwAaCHS0tIkSc8884zmzZvn4mgAAI7SYILn0KFD6tatmxNDAQC40o4dO/TYY4+pQ4cO+v7775WcnKz58+dr0KBBrg4NANAMLkzuWK3WWvcZjUZnhwMAuEINJngWL16szZs3S5Luu+8+rV271mlBAQCc74cfflCHDh0kSZ06dZKvry/JHQBowQ4ePKgNGzbo8OHDqqysrHUfi60AgOdpMMHj7++vjz/+WJ07d5bFYlFRUZFsNlud7Wq+DAAAPJvNZqvV13t5edXp++nzAaDlSEtL080336x77rlHrVq1cnU4AIAr1GCCJykpSZs2bVJJSYmsVqvuvffeercjuw8ALcPZs2fr9PUX36bPB4CWo6SkRFOnTpXBYHB1KAAAB2gwwTNgwAANGDBAkjR9+nRt2bLFaUEBAJyP5A0AXF369++vTz/9VFFRUa4OBQDgAI1aRWvjxo2Szk++VlZWpsDAQCZeAwAAADzYuXPn9OSTT6pXr14KCgqqdR+rawGA52lUgufcuXNat26dPvzwQ1mtVnl5eSkuLk533HGH/P39mztGAAAAAA7WuXNnde7c2dVhAAAcpNEjeM6cOaOUlBSFhYWpuLhYW7du1caNG8nuAwAAAB5o0qRJrg4BAOBAjUrw5Ofn65lnnrHPrh8eHq45c+Y0OPEyAMCzHDp0SN26dXN1GAAAJzh+/PhPbsOqiQDgeRqV4PH19VV5ebnCwsLsZeXl5fL2btTuAAA3t3jxYm3evFmSdN9992nt2rUujggA0Fzuu+++n9yGifcBwPM0KkMzfPhwPf744xozZoz9Eq23335bCQkJzR0fAMAJ/P399fHHH6tz586yWCwqKiqSzWarsx2/6AKA5yN5AwAtU6MSPImJiQoODtaHH34os9ksk8mk8ePH65Zbbmnu+AAATpCUlKRNmzappKREVqu1wUtw+VIAAAAAuKdGJXgMBoOGDx+u4cOHN3c8AAAXGDBggAYMGCBJmj59urZs2eLiiAAAAABcDqOrAwAAuJeNGzdKkqxWqywWi6xWq4sjAgAAAPBTmCUZAFDLuXPntG7dOn344YeyWq3y8vJSXFyc7rjjDvn7+7s6PADAFWDVRABouRjBAwCoZePGjTpz5oxSUlL08ssv68knn1RlZaV9ZA8AwHMtXrzY/n9jVtMCAHiORiV4duzYUW/5zp07HRoMAMD18vPzde+99yo8PFw+Pj4KDw/XnDlz9Omnn7o6NADAFapZNfH48eP2VROPHz9e5w8A4HkadYnWunXrFBsbW6f8ueee06BBgxweFADAdXx9fVVeXq6wsDB7WXl5uby9uaoXADwdqyYCQMt1yU/rNdl7q9WqoqIi2Wy2Wvf5+vo26iDp6enas2ePAgMDlZKSIknatm2b3nvvPbVr106SNHXqVN10002SpO3btysrK0tGo1FJSUmKioqSJB08eFBpaWmqrKxUdHS0kpKSZDAYLq/GAIBLGj58uB5//HGNGTNGYWFhKi4u1ttvv62EhARXhwYAuEKsmggALdclEzwXXpd7cXY/KChIkyZNatRBhg0bplGjRiktLa1W+ZgxYzRu3LhaZYWFhcrNzdXq1atlsVi0dOlSrVmzRkajUevXr9fs2bMVGRmp5cuXKz8/X9HR0Y2KAQDQOImJiQoODtaHH34os9ksk8mk8ePH65ZbbnF1aAAAB7pw1cSysjIFBgbKaGSKTgDwVJdM8NQMzVy8eLEee+yxJh+kT58+KioqatS2eXl5iouLk4+Pj9q3b6+OHTuqoKBAYWFhqqioUM+ePSVJQ4cOVV5eHgkeAHAwg8Gg4cOHa/jw4a4OBXCJ06vKmrRfmwWBDo4EaF6smggALUujJlS4kuTOpbz77rvKyclR9+7dNX36dAUEBMhsNisyMtK+jclkktlslpeXl0JCQuzlISEhMpvNDT52ZmamMjMzJUkrVqxQaGhos9TB0Twlzubi7e191bdBDdriPNrhx36BtgAAONKFqybWXJK7detWbdy4UfPmzXN1eACAy9SoBE9RUZFeffVVHTp0SGfOnKl137PPPtukA996662aOHGipPMjhbZs2aI5c+bUmufnQg2VNyQhIaHWfBElJSVNitPZPCXO5hIaGnrVt0EN2uI82uHHfqEpbREeHt4cIQEAWoD8/Hw988wzatWqlSTZV01saOJlAIB7a1SCZ82aNerQoYOmT59ufwO4UkFBQfb/R4wYoZUrV0o6PzKntLTUfl/N/A8Xl5eWlspkMjkkFgAAAOBqw6qJANCyNKr3Liws1NKlSx066ZrFYlFwcLAkadeuXerSpYskKSYmRmvXrtXYsWNlsVh09OhRRUREyGg0ys/PT/v371dkZKRycnI0atQoh8UDADhvx44dio2NrVO+c+dODRo0yAURAQCagyNWTbRarXrwwQdlMpn04IMP6tSpU0pNTVVxcbHCwsI0f/58BQQESGKlXABobo1K8PTu3VuHDh1S9+7dm3SQp556Sl999ZVOnjypu+++W5MnT9aXX36pQ4cOyWAwKCwsTHfddZckqUuXLoqNjVVycrKMRqNmzpxpTyzNmjVL6enpqqysVFRUFBMsA0AzWLduXb0Jnueee44EDwC0II5YNfEf//iHOnXqpIqKCklSRkaG+vbtqwkTJigjI0MZGRmaNm0aK+UCgBM0KsETFhamZcuWacCAAbUurZKkKVOm/OT+DzzwQJ2yS63OkpiYqMTExDrlPXr0UEpKyk8eDwBw+Y4fPy7p/K+xRUVFteY+O378uHx9fV0VGgCgGVzpqomlpaXas2ePEhMT9dZbb0k6vyLukiVLJEnx8fFasmSJpk2bxkq5AOAEjUrwnD17VjfffLOqq6trzYMDAGg57rvvPvv/F0+wGRQUpEmTJjk7JACAG9u0aZOmTZtmH70jSWVlZfZpGIKDg1VeXi5JHrtSbktfwbKl109q+XWkfp4rNDTU4fVrVIJnzpw5DjsgAMA9vfbaa5KkxYsX67HHHnNxNAAAd/bxxx8rMDBQ3bt315dffvmT23vqSrktfTXPll4/qeXXkfq5XlPXrC0pKWly/RpaKbdRCZ6aYfv16dChw2UHAwBwXyR3AAA/Zd++fdq9e7c++eQTVVZWqqKiQmvXrlVgYKB9MRWLxaJ27dpJYqVcAHCGRiV4Lhy2f7GaX3wBAC1DUVGRXn31VR06dEhnzpypdd+zzz7roqgAAI52Jasm/va3v9Vvf/tbSdKXX36pN998U/fdd59eeuklZWdna8KECcrOzlb//v0lsVIuADhDoxI8FydxTpw4oddff129e/dulqAAAK6zZs0adejQQdOnT1erVq1cHQ4AoJk0x6qJEyZMUGpqqrKyshQaGqrk5GRJrJQLAM7QqATPxYKCgjRjxgzdf//9Gjx4sKNjAgC4UGFhoZYuXWr/4A0AaFkcvWriz372M/3sZz+TJLVt21aLFi2qdztWygWA5tWkBI8kHTlyRGfPnnVkLAAAN9C7d28dOnRI3bt3d3UoAIBmwKqJANAyNSrBs2jRIhkMBvvts2fP6rvvvtPEiRObLTAAgGuEhYVp2bJlGjBggIKCgmrdN2XKFNcEBQAe5PSqsibvG7qy+ZcDZtVEAGiZGpXgGT58eK3brVu31rXXXqtrrrmmWYICALjO2bNndfPNN6u6urrWyiaNlZ6erj179igwMNA+5P7UqVNKTU1VcXGxwsLCNH/+fAUEBEiStm/frqysLBmNRiUlJSkqKkqSdPDgQaWlpamyslLR0dFKSkqq9WMDAODKkNwBgJalUQmeYcOGNXMYAAB3MWfOnCvaf9iwYRo1apTS0tLsZRkZGerbt68mTJigjIwMZWRkaNq0aSosLFRubq5Wr14ti8WipUuXas2aNTIajVq/fr1mz56tyMhILV++XPn5+Uy8CQAOxKqJANCyNCrBU1VVpb/+9a/KycmRxWJRcHCwhg4dqsTERHl7N3kaHwCAG6qZfLM+HTp0+Mn9+/Tpo6KiolpleXl5WrJkiSQpPj5eS5Ys0bRp05SXl6e4uDj5+Pioffv26tixowoKChQWFqaKigr17NlTkjR06FDl5eWR4AEAB2LVRABoWRqVnXn55Zd14MAB3XnnnQoLC1NxcbHeeOMN/fDDD5oxY0YzhwgAcKYLJ9+8WM28DZerrKxMwcHBkqTg4GCVl5dLksxmsyIjI+3bmUwmmc1meXl5KSQkxF4eEhIis9lc72NnZmYqMzNTkrRixQqFhjp2/gpvb2+HP6ajuXuMVxLfaTV9LhNna+5z4O7nWXL/GJ0V35U8b53ZhqyaCAAtS6MSPDt37tSqVavUtm1bSVJ4eLiuu+46LViwgAQPALQwFydxTpw4oddff129e/d2+LEuXJq3MeX1SUhIUEJCgv12SUnJFcd1odDQUIc/pqO5e4zuHp+jNHcdPaEd3T1Gd49POj9yvikxhoeHX/Y+rJoIAC1LoxI8l/NBGwDQsgQFBWnGjBm6//77NXjw4CY9RmBgoP0SX4vFonbt2kk6PzLnwomczWazTCZTnfLS0lKZTKYrqwgAoBZWTQSAlqVR4zFjY2O1cuVK5efnq7CwUPn5+Vq1apViY2ObOz4AgBs4cuSIzp492+T9Y2JilJ2dLUnKzs5W//797eW5ubk6d+6cioqKdPToUUVERCg4OFh+fn7av3+/bDabcnJyFBMT45C6AADOu3jVxAv/AACep1EjeKZNm6Y33nhDGzZskMVikclkUlxcnG677bbmjg8A4GSLFi2qtRz52bNn9d1332nixImN2v+pp57SV199pZMnT+ruu+/W5MmTNWHCBKWmpiorK0uhoaFKTk6WJHXp0kWxsbFKTk6W0WjUzJkz7XNBzJo1S+np6aqsrFRUVBQTLAOAg13pqokAAPfSqASPt7e3pkyZwlBNALgKDB8+vNbt1q1b69prr9U111zTqP0feOCBessXLVpUb3liYqISExPrlPfo0UMpKSmNOiYA4PJd6aqJAAD3cskEz969e7V7925Nmzatzn2vvPKK+vfvb1/CFgDQMgwbNszVIQAAnKA5Vk0EALjOJRM827dv18iRI+u9r0+fPvrrX/+qBx98sFkCAwC4RlVVlf76178qJyfHPjHy0KFDlZiYKG/vRg38BAB4AGeumggAaH6XnGT50KFDioqKqve+fv366dtvv22OmAAALvTyyy/r888/15133qlVq1bpzjvv1BdffKGXX37Z1aEBAJpRzaqJf/nLX1wdCgCgCS75U2xFRYWqqqrk6+tb577q6mpVVFQ0W2AAANfYuXOnVq1apbZt20qSwsPDdd1112nBggWaMWOGa4MDADSrK101EQDgOpdM8HTq1EmffvqpfTnbC3366afq1KlTswUGAHANm83m6hDQwvzfwgOuDgFAPa501UQAgHu5ZIJnzJgxev7552W1WtW/f38ZjUZZrVbl5eVpw4YNmj59urPiBAA4SWxsrFauXKmJEycqNDRUJSUleuONNxQbG+vq0AAADnSlqyYCANzLJRM8gwcP1okTJ5SWlqZz586pXbt2Ki8vl6+vryZNmqTBgwc7K04AgJNMmzZNb7zxhjZs2CCLxSKTyaS4uDjddtttrg4NAOBArJoIAC3LTy6HMnbsWA0fPlz79+/XqVOnFBAQoJ49e8rf398Z8QEAnMzb21tTpkzRlClTXB0KAKAZsWoiALQsjeq5/f39G1xNCwDQMuzdu1e7d+/WtGnT6tz3yiuvqH///urZs6cLIgMANIeXX35ZBw4c0J133qmwsDAVFxfrjTfe0A8//MCk+gDggS65TDoA4Oqxfft29enTp977+vTpo7/+9a9OjggA0Jx27typ//7v/9aNN96o8PBw3XjjjfrDH/6gHTt2uDo0AEATkOABAEiSDh061OBozX79+unbb791bkAAgGbFqokA0LJwcS0AQJJUUVGhqqoq+fr61rmvurpaFRUVLogKANBcWDURAFoWEjwAAElSp06d9Omnn6p///517vv000/VqVMnF0QFAGgurJoIAC0LCR4AgCRpzJgxev7552W1WtW/f38ZjUZZrVbl5eVpw4YNmj59uqtDBAA4EKsmAkDL4pQET3p6uvbs2aPAwEClpKRIkk6dOqXU1FQVFxcrLCxM8+fPV0BAgKTzE31mZWXJaDQqKSnJPifEwYMHlZaWpsrKSkVHRyspKUkGg8EZVQCAFm/w4ME6ceKE0tLSdO7cObVr107l5eXy9fXVpEmTNHjwYFeHCABwAFZNBICWySkJnmHDhmnUqFFKS0uzl2VkZKhv376aMGGCMjIylJGRoWnTpqmwsFC5ublavXq1LBaLli5dqjVr1shoNGr9+vWaPXu2IiMjtXz5cuXn5ys6OtoZVQCAq8LYsWM1fPhw7d+/X6dOnVJAQIB69uwpf39/V4cGAHCQ7du3a+TIkfXeV7Nq4oMPPujkqAAAV8opq2j16dPHPjqnRl5enuLj4yVJ8fHxysvLs5fHxcXJx8dH7du3V8eOHVVQUCCLxaKKigr17NlTBoNBQ4cOte8DAHAcf39/RUVFafDgwYqKiiK5AwAtDKsmAkDL5LI5eMrKyhQcHCxJCg4OVnl5uSTJbDYrMjLSvp3JZJLZbJaXl5dCQkLs5SEhITKbzQ0+fmZmpjIzMyVJK1asUGhoaHNUw+E8Jc7m4u3tfdW3QQ3a4jza4cd+gbYAADgCqyYCQMvkdpMs22y2yypvSEJCghISEuy3S0pKriguZ/GUOJtLzRKdoC1q0A4/9gtNaYvw8PDmCAkA4MFYNREAWianXKJVn8DAQFksFkmSxWJRu3btJJ0fmVNaWmrfzmw2y2Qy1SkvLS2VyWRybtAAAACAh6tZNfGjjz6S1WqVJFmtVn300Udav369xowZ4+IIAQBN4bIRPDExMcrOztaECROUnZ1t/wUhJiZGa9eu1dixY2WxWHT06FFFRETIaDTKz89P+/fvV2RkpHJycjRq1ChXhQ/gKtVp/XpXhwAAwBVh1UQAaJmckuB56qmn9NVXX+nkyZO6++67NXnyZE2YMEGpqanKyspSaGiokpOTJUldunRRbGyskpOTZTQaNXPmTBmN5wcazZo1S+np6aqsrFRUVBQraAEAAABNwKqJANDyOCXB88ADD9RbvmjRonrLExMTlZiYWKe8R48eSklJcWRoAAAAwFWpZtVEAEDL4LI5eAAAAAAAAOAYJHgAAAAAAAA8HAkeAAAAAAAAD0eCBwAAAAAAwMOR4AEAAAAAAPBwJHgAAAAAAAA8HAkeAAAAAAAAD0eCBwAAAAAAwMOR4AEAAAAAAPBwJHgAAAAAAAA8HAkeAAAAAAAAD0eCBwAAAAAAwMOR4AEAAAAAAPBw3q4OAABcodP69a4OAQAAAAAchgQPAAAAgMtWUlKitLQ0nThxQgaDQQkJCRo9erROnTql1NRUFRcXKywsTPPnz1dAQIAkafv27crKypLRaFRSUpKioqIkSQcPHlRaWpoqKysVHR2tpKQkGQwGF9YOADwPl2gBAAAAuGxeXl66/fbblZqaqmXLlundd99VYWGhMjIy1LdvX61du1Z9+/ZVRkaGJKmwsFC5ublavXq1Hn74YW3YsEFWq1WStH79es2ePVtr167VsWPHlJ+f77qKAYCHIsEDAAAA4LIFBwere/fukiQ/Pz916tRJZrNZeXl5io+PlyTFx8crLy9PkpSXl6e4uDj5+Pioffv26tixowoKCmSxWFRRUaGePXvKYDBo6NCh9n0AAI3HJVoAAAAArkhRUZG+/fZbRUREqKysTMHBwZLOJ4HKy8slSWazWZGRkfZ9TCaTzGazvLy8FBISYi8PCQmR2Wyu9ziZmZnKzMyUJK1YsUKhoaHNVSVJkre3d7Mfw5Vaev2kll9H6ue5QkNDHV4/EjwAAAAAmuzMmTNKSUnRjBkz5O/v3+B2Npvtssrrk5CQoISEBPvtkpKSxgfaBKGhoc1+DFdq6fWTWn4dqZ/rhTdxv5KSkibXLzy8/qOS4AEAOM3cuXPVunVrGY1GeXl5acWKFU2ajBMA4B6qqqqUkpKiIUOGaODAgZKkwMBAWSwWBQcHy2KxqF27dpLOj8wpLS2172s2m2UymeqUl5aWymQyObciANACMAcPAMCpFi9erFWrVmnFihWS1KTJOAEArmez2bRu3Tp16tRJY8eOtZfHxMQoOztbkpSdna3+/fvby3Nzc3Xu3DkVFRXp6NGjioiIUHBwsPz8/LR//37ZbDbl5OQoJibGJXUCAE9GggcA4FKXOxknAMA97Nu3Tzk5Ofriiy+0YMECLViwQHv27NGECRP02Wef6b777tNnn32mCRMmSJK6dOmi2NhYJScna9myZZo5c6aMxvNfR2bNmqXnnntO9913nzp06KDo6GgX1gwAPBOXaAEAnGrZsmWSpF/84hdKSEi47Mk4AQDuoVevXtq2bVu99y1atKje8sTERCUmJtYp79Gjh1JSUhwaHwBcbUjwAPBYndavd3UIuExLly6VyWRSWVmZHn/88QYniJMaP+lmc6+o4gmrN7h7jKdV5uoQnILVfNw/RmfFdyXPeXdvQwCA+yLBAwBwmppJMwMDA9W/f38VFBRc9mScF2vuFVU8YfUGT4jxasBqPu4fo7vHJ52ftNiRK6oAAK4eJHgAAE5x5swZ2Ww2+fn56cyZM/rss880ceJE+2ScEyZMqDMZ59q1azV27FhZLBb7ZJwA4CynV10do88AAC0DCR4AgFOUlZXpySeflCRVV1dr8ODBioqKUo8ePZSamqqsrCyFhoYqOTlZUu3JOI1GY63JOAEAAADURoIHAOAUHTp00KpVq+qUt23b9rIn4wQAAABQGz+FAgAAAAAAeDgSPAAAAAAAAB6OS7QAuBRLnQMAAADAlXN5gmfu3Llq3bq1jEajvLy8tGLFCp06dUqpqakqLi5WWFiY5s+fr4CAAEnS9u3blZWVJaPRqKSkJEVFRbm2AgAAAAAAAC7m8gSPJC1evFjt2rWz387IyFDfvn01YcIEZWRkKCMjQ9OmTVNhYaFyc3O1evVqWSwWLV26VGvWrGFVFQAAAAAAcFVzy8xIXl6e4uPjJUnx8fHKy8uzl8fFxcnHx0ft27dXx44dVVBQ4MpQAQAAAAAAXM4tRvAsW7ZMkvSLX/xCCQkJKisrU3BwsCQpODhY5eXlkiSz2azIyEj7fiaTSWazud7HzMzMVGZmpiRpxYoVCg0Nbc4qOIynxNlcvL29r/o2qEFboEbN84DnBAAAAICGuDzBs3TpUplMJpWVlenxxx9XeHh4g9vabLZGP25CQoISEhLst0tKSq4oTmfxlDibS2ho6FXfBjVoC9SoeR405TlxqT4VAAAAQMvh8ku0TCaTJCkwMFD9+/dXQUGBAgMDZbFYJEkWi8U+P09ISIhKS0vt+5rNZvv+AAAAAAAAVyuXjuA5c+aMbDab/Pz8dObMGX322WeaOHGiYmJilJ2drQkTJig7O1v9+/eXJMXExGjt2rUaO3asLBaLjh49qoiICFdWAcD/x3LnAAAAAOA6Lk3wlJWV6cknn5QkVVdXa/DgwYqKilKPHj2UmpqqrKwshYaGKjk5WZLUpUsXxcbGKjk5WUajUTNnzmQFLQAAAAAAcNVzaYKnQ4cOWrVqVZ3ytm3batGiRfXuk5iYqMTExOYODQAAXOD0qjJXhwAAAIBLYPgLAAAAAACAhyPBAwAAAAAA4OFI8AAAAAAAAHg4l87BA8C9sBIWAAAAAHgmEjxAC0SiBgAAAACuLlyiBQAAAAAA4OFI8AAAAAAAAHg4EjwAAAAAAAAejgQPAAAAAACAhyPBAwAAAAAA4OFI8AAAAAAAAHg4lkkH3FSr5ctdHQIAAAAAwEMwggcAAAAAAMDDkeABAAAAAADwcFyiBQAAgBbr9KqyH/9X2SW2BADAs5HgAQAAcIALEwmXq82CQAdGAgAArkZcogUAAAAAAODhGMEDAAAAAACuWuHvd3J1CA7BCB4AAAAAAAAPR4IHAAAAAADAw5HgAQAAAAAA8HDMwQMAAAC3diUrlAEAcLUgwQMAgBr+Anlal/5iyfLWAAAAcAckeAAAuAJXMrLAFckhRkIAAAC0TMzBAwAAAAAA4OEYwQMAAACnYAQZAADNhxE8AAAAAAAAHo4EDwAAAAAAgIfjEi0AAFykqZersHIXAOCnhL/fqXHb1VN2ZNj3jg0GgFOQ4AEAAECjXSoxeVrMsQMAgKuQ4AEAwMNc/AWbL9VXLyYtBgAANTwywZOfn68XX3xRVqtVI0aM0IQJE1wdEtCgTuvXuzoEwGPR3wPA1YM+H8CVaOxliS2ZxyV4rFarNmzYoEceeUQhISH64x//qJiYGHXu3NnVoQEAHIj+HleTxozEYaQWWjL6fAC4ch6X4CkoKFDHjh3VoUMHSVJcXJzy8vKapfNn5AUAuI4z+3sAgGvR5wOocfFInPomAkf9PC7BYzabFRISYr8dEhKib775ps52mZmZyszMlCStWLFC4eGX/7SwLV7c9EDRZE05V+6M5xEcqaW9Pi7Fmf29JCn16mlbAO7taurrazi9z78MHns+fmtr8q4eWuMGeew5bKQWV78reO56kpqz5sjzZ3TYIzmJzVb3ZBsMhjplCQkJWrFihVasWOGMsK7Ygw8+6OoQ3ALt8CPa4jza4UdXW1u4S3/vCe3u7jG6e3wSMTqKu8fo7vFJnhFjc3CXPv9iLf18tPT6SS2/jtTPszm6fh6X4AkJCVFpaan9dmlpqYKDg10YEQCgOdDfA8DVgz4fAK6cxyV4evTooaNHj6qoqEhVVVXKzc1VTEyMq8MCADgY/T0AXD3o8wHgynncHDxeXl664447tGzZMlmtVt1yyy3q0qWLq8O6YgkJCa4OwS3QDj+iLc6jHX50tbWFu/T3ntDu7h6ju8cnEaOjuHuM7h6f5BkxNgd36fMv1tLPR0uvn9Ty60j9PJuj62ew1XfBKwAAAAAAADyGx12iBQAAAAAAgNpI8AAAAAAAAHg4j5uDx9Pt2LFDr7/+ur7//ns98cQT6tGjh/2+7du3KysrS0ajUUlJSYqKipIkHTx4UGlpaaqsrFR0dLSSkpLqXTbSk23btk3vvfee2rVrJ0maOnWqbrrpJkkNt0tLlZ+frxdffFFWq1UjRozQhAkTXB2SU82dO1etW7eW0WiUl5eXVqxYoVOnTik1NVXFxcUKCwvT/PnzFRAQ4OpQHSo9PV179uxRYGCgUlJSJOmS9b7aXhfO8s9//lPvvPOOvLy8dNNNN2natGmS3Kd/bkpf6ar3kL///e96+eWX9cILL9jjdYcYt27dqt27d8tgMCgwMFBz5syRyWRym/gk6aWXXtLHH38sb29vdejQQXPmzFGbNm3cKkZP/DzjLu+v9Pfuq6HndVFRkebPn6/w8HBJUmRkpO666y5Jrn9eXw5PfN021dXw3cJd+jRHaonfA5ze59vgVN99953t+++/ty1evNhWUFBQq/wPf/iDrbKy0nb8+HHbvHnzbNXV1TabzWZ78MEHbfv27bNZrVbbsmXLbHv27HFV+M3mtddes/3tb3+rU36pdmmJqqurbfPmzbMdO3bMdu7cOdsf/vAH23fffefqsJxqzpw5trKyslplL730km379u02m81m2759u+2ll15yQWTN68svv7QdOHDAlpycbC9rqN5X2+vCWT7//HPbn/70J1tlZaXNZrPZTpw4YbPZ3Kt/bkpf6Yr3kOLiYtvjjz9uu+eee+yvZ3eJ8fTp0/b/3377bdtzzz3nVvHZbDZbfn6+raqqymazne8HGvPad3aMnvZ5xp3eX+nv3VdDz+vjx4/XOl8X8qTP6Z72ur0SLf27hTv1aY7UEr8HOLvP5xItJ+vcubM9+3+hvLw8xcXFycfHR+3bt1fHjh1VUFAgi8WiiooK9ezZUwaDQUOHDlVeXp4LIneNhtqlpSooKFDHjh3VoUMHeXt7Ky4u7qo63w3Jy8tTfHy8JCk+Pr5FtkmfPn3q/BrRUL2vtteFs/zrX//S+PHj5ePjI0kKDAyU5Bn9s7vFuHnzZv3ud7+r9Suvu8To7+9v///s2bP2GN0lPkm68cYb5eXlJUnq2bOnzGaz28XoaZ9n3On9lf7efTX0vG6Iq5/Xl8vTXrfNoaW8ptypT2tunv49wNl9PpdouQmz2azIyEj7bZPJJLPZLC8vL4WEhNjLQ0JC7B/0Wpp3331XOTk56t69u6ZPn66AgIAG26WlMpvNdc73N99848KIXGPZsmWSpF/84hdKSEhQWVmZgoODJUnBwcEqLy93ZXhO01C9r7bXhbMcPXpUe/fu1datW+Xj46Pbb79dERERbtc/X05f6YoYd+/eLZPJpG7dutUqd6cYX331VeXk5Mjf31+LFy92u/gulJWVpbi4OLeO8ULuGqO7v7/S37u/oqIi/fd//7f8/Pz0m9/8Rr179673eeWJ58ddX7dXqiV/t3D3Pu1KXA3fA5qzzyfB0wyWLl2qEydO1Cn/zW9+o/79+9e7j62B1eobKvdEl2qXW2+9VRMnTpQkvfbaa9qyZYvmzJnTourfGPXV1xOuc3akpUuXymQyqaysTI8//vhl/ZJ2tbjaXheOdKl+yGq16tSpU1q2bJkOHDig1NRUPfPMM07vnx3ZV7oixu3bt+uRRx5pdCzNEeNPvQ9PnTpVU6dO1fbt2/XOO+9o8uTJbtWGNZ8V/vrXv8rLy0tDhgy5ZCyujLGxsbi63/LU91dXt1tL1JTndXBwsNLT09W2bVsdPHhQq1atUkpKiluen5b0uv0pV/N3C0/t037K1f49wBHPTxI8zeDRRx+97H1CQkJUWlpqv202m2UymeqUl5aW2ieD9DSNbZcRI0Zo5cqVkhpul5aqvvNdk929WtSc38DAQPXv318FBQUKDAyUxWJRcHCwLBaLfcK8lq6hel9trwtHulQ/9K9//UsDBw6UwWBQRESEjEajTp486fT+2ZF9pbNjPHz4sIqKirRgwQL78RYuXKjly5c7NcbGtuHgwYO1YsUKTZ482W3asMb777+vjz/+WIsWLbJ/aHe3GOvjrp9n3P39lf7eeZryvPbx8bFfvtu9e3d16NBBR48edfnzuj4t6XX7U67m7xbu3qc11dXyPaA5+3zm4HETMTExys3N1blz51RUVKSjR48qIiJCwcHB8vPz0/79+2Wz2ZSTk6OYmBhXh+twFovF/v+uXbvUpUsXSQ23S0vVo0cPHT16VEVFRaqqqlJubm6LPN8NOXPmjCoqKuz/f/bZZ+ratatiYmKUnZ0tScrOzm7wF6iWpqF6X22vC2fp37+/vvjiC0nSkSNHVFVVpbZt27pV/3y5faWzY+zatateeOEFpaWlKS0tTSEhIVq5cqWCgoLcJsajR4/a/9+9e7f910F3iU86vzLK3/72Ny1cuFCtWrWyl7tTjA1x1xjd/f2V/t69lZeXy2q1SpKOHz+uo0ePqkOHDi5/XjuKu75ur0RL/27h7n1aU1xN3wOas8832FrKODUPsWvXLm3cuFHl5eVq06aNunXrpocffljS+aHY//73v2U0GjVjxgxFR0dLkg4cOKD09HRVVlYqKipKd9xxR4sYgnehp59+WocOHZLBYFBYWJjuuusuexa6oXZpqfbs2aPNmzfLarXqlltuUWJioqtDcprjx4/rySeflCRVV1dr8ODBSkxM1MmTJ5WamqqSkhKFhoYqOTnZo5ZHbIynnnpKX331lU6ePKnAwEBNnjxZ/fv3b7DeV9vrwhmqqqqUnp6u//u//5O3t7duv/123XDDDZLcp39uSl/pyveQuXPnavny5fZfptwhxieffFJHjx6VwWBQaGio7rrrLvuvY+4QnyTde++9qqqqsr/eL1yS2V1i9MTPM+7y/kp/774ael7v3LlT27Ztk5eXl4xGoyZNmmT/Mu3q5/Xl8MTXbVNdDd8t3KVPc5SW+j3A2X0+CR4AAAAAAAAPxyVaAAAAAAAAHo4EDwAAAAAAgIcjwQMAAAAAAODhSPAAAAAAAAB4OBI8AAAAAAAAHo4ED+AiTzzxhN5//31XhwEAcLBt27Zp7dq1rg4DAHAF0tLStHXrVknSl19+qbvvvtt+X3Jysr788ktXhQY0yNvVAQCeYO7cuTpx4oSMRqO8vb3Vs2dP3XnnnQoNDW3yYz700EMOjBAA8FMu7Mtbt26tqKgozZw5U61bt3Z1aACAJpo7d65mz56tfv36XXK7JUuWaMiQIRoxYsQVH3P16tVX/BiN0di6ATUYwQM00sKFC/XSSy/pueeeU2BgoDZu3OjqkAAAl6mmL1+1apUOHTqk7du3uzokAAAAh2AED3CZfH19NWjQIG3evFmStGfPHm3dulXHjx+Xv7+/brnlFk2ePFmSVFlZqXXr1ik/P19Wq1XXXHONFi5cqKCgoDq/ImRmZurtt99WaWmpQkJCdO+996p79+4uqycAtGRBQUG68cYbdejQIUlSRkaG3nvvPZWVlSkkJERTp07VgAEDJEnvv/++3nvvPUVGRurf//63/P39NWvWLEVHR0uSioqKlJaWpm+//VaRkZEKDw+vdazdu3frL3/5i8xms7p166ZZs2apc+fOks7/Ojty5Ejl5OTo+PHjiouL09SpU5Wenq69e/cqMjJS8+fPV0BAgPMaBwA80KX66ldffVVff/21vvnmG23atEnDhg3TzJkz9f3332vjxo06ePCg2rVrpylTpiguLu4nj3XhyJrKyko9//zz+vjjjxUUFKRhw4bpn//8p9atWydJMpvN2rhxo77++mu1bt1aY8aM0ejRoyWdv6S3sLBQvr6+2rVrl0JDQzV37lz16NFDTz/9tEpKSrRy5UoZjUZNnDhR48ePb9Y2hOdjBA9wmc6ePavc3FxFRkZKklq1aqV58+bpxRdf1IMPPqj//d//1a5duyRJ2dnZ+uGHH/Tss89q48aNuvPOO+Xr61vnMXfs2KHXX39dc+fO1ebNm7Vw4UK1bdvWqfUCgKtJaWmpPvnkE3Xs2FGS1KFDBz322GPatGmTJk2apKeffloWi8W+fUFBgcLDw7VhwwaNHz9e69atk81mkyStWbNG3bt314YNG3TbbbcpOzvbvt+RI0e0Zs0azZgxQy+88IKio6O1cuVKVVVV2bf56KOP9Mgjj2jNmjX6+OOPtXz5ck2dOlUbNmyQ1WrVP//5Tye1CgB4tob66qlTp6p3796644479NJLL2nmzJk6c+aMHn/8cQ0ePFgvvPCC7r//fm3YsEHffffdZR3z9ddfV3FxsZ5++mk98sgj+uCDD+z3Wa1WrVy5Ut26ddNzzz2nRYsW6R//+Ify8/Pt23z88ceKi4vTpk2bFBMTY79K4N5771VoaKh95CnJHTQGCR6gkVatWqUZM2bo97//vT7//HONGzdOkvSzn/1MXbt2ldFo1LXXXquf//zn+uqrryRJXl5eOnXqlI4dOyaj0aju3bvL39+/zmNnZWVp/PjxioiIkMFgUMeOHRUWFubU+gHA1WDVqlWaPn267rnnHgUGBtpHXMbGxspkMsloNCouLk4dO3ZUQUGBfb/Q0FAlJCTIaDQqPj5eFotFZWVlKikp0YEDBzRlyhT5+PioT58+uvnmm+375ebmKjo6Wv369ZO3t7d+9atfqbKyUvv27bNvM2rUKAUFBclkMqlXr16KiIjQddddJx8fHw0YMEDffvut8xoIADxYQ311ffbs2aOwsDDdcsst8vLyUvfu3TVw4EDt3Lnzso65Y8cO/frXv1ZAQIBCQkL0y1/+0n7fgQMHVF5erokTJ8rb21sdOnTQiBEjlJuba9+mV69euummm2Q0GjV06FD7yFKgKbhEC2ikBQsWqF+/frJarcrLy9PixYuVmpqq4uJi/eUvf9Hhw4dVVVWlqqoqDRo0SJI0dOhQlZaW6qmnntIPP/ygIUOG6De/+Y28vWu/9EpKStShQwdXVAsArio1fflXX32lNWvW6OTJk2rTpo2ys7P11ltvqbi4WJJ05swZnTx50r5fUFCQ/f9WrVrZtykvL1ebNm1qTdQcFhamkpISSZLFYqmVsDcajQoNDZXZbLaXBQYG2v/39fWtc/vs2bMOqj0AtGwN9dX1KS4u1jfffKMZM2bYy6qrqzV06NDLOqbFYqm18EpISEitY1gsllrHsFqt6t27t/32xX3+uXPnVF1dLS8vr8uKA5BI8ACXzWg0auDAgXr++ee1d+9evfLKKxo5cqT++Mc/ytfXV5s2bVJ5ebkkydvbW5MmTdKkSZNUVFSk5cuXKzw8XMOHD6/1mKGhoTp+/LgrqgMAV6U+ffpo2LBh2rJli5KSkuxD53v27Cmj0agFCxbYL8G6lODgYJ0+fVpnzpyxJ3lqkjs19x8+fNh+22azqaSkRCaTyfGVAgA0yGAw1LodEhKiPn366NFHH72ixw0KClJpaal9brXS0lL7faGhoWrfvr3Wrl17RccAGotLtIDLZLPZlJeXp9OnT6tTp06qqKhQQECAfH19VVBQoP/85z/2bb/44gsdPnxYVqtV/v7+8vb2ltFY92U3fPhwvfnmmzp48KBsNpuOHTtm/xUZANA8xowZo88//1xms1kGg0Ht2rWTJP373/9u9BwMYWFh6tGjh7Zt26aqqirt3btXH3/8sf3+uLg4ffLJJ/r8889VVVWlN998Uz4+Prr++uubpU4AgPoFBgbW+kH15ptv1tGjR5WTk2MfhV9QUKDCwsLLetzY2FhlZGTo1KlTMpvNeuedd+z3RUREyM/PTxkZGaqsrJTVatXhw4drXQJ8KUFBQSoqKrqseHB1YwQP0Eg1M9gbDAaFhYVp7ty56tKli2bNmqUtW7Zo48aN6tOnj2JjY3X69GlJ0okTJ7R+/XqZzWa1bt1asbGxGjJkSJ3Hjo2N1cmTJ7VmzRqZzWa1b99e8+bNYx4eAGhG7dq109ChQ/Xmm29q7Nixevjhh+1zIFxOAua+++5TWlqakpKS1LNnTw0dOtT+PhAeHq57771XGzdutK+itXDhwjqX6gIAmtfo0aOVlpam//3f/9WQIUN0xx136JFHHtHmzZu1efNm2Ww2XXvttfr9739/WY87ceJErV+/XvPmzVNwcLAGDx6s999/X9L5kf8LFy7Uli1bNHfuXFVVVSk8PFxTpkxp1GNPmDBBGzdu1Msvv6zExET7HKBAQwy2xow/BgAAAAAAl/Svf/1LH374oR577DFXh4KrEJdoAQAAAADQBBaLRXv37pXVatWRI0f05ptvasCAAa4OC1cpxgcDAAAAANAEVVVVWr9+vYqKiuTv76+f//znGjlypKvDwlWKS7QAAAAAAAA8HJdoAQAAAAAAeDgSPAAAAAAAAB6OBA8AAAAAAICHI8EDAAAAAADg4UjwAAAAAAAAeLj/B3TMuyBX/feeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x360 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(16,5))\n",
    "\n",
    "feature_cols = [runs_df.basic, runs_df.random, runs_df.intell]\n",
    "names = ['Basic', 'Random', 'Intelligent']\n",
    "colors = ['teal', 'orchid', 'orange']\n",
    "\n",
    "for i in range(len(feature_cols)):\n",
    "    ax[i].hist(feature_cols[i], color= colors[i], bins=20)\n",
    "    ax[i].set_xlabel(names[i])\n",
    "    ax[i].set_ylabel(\"Count of \" + names[i])\n",
    "    ax[i].set_title(\"Histogram of \"+ names[i] +\"\\n\", fontsize = (16))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
